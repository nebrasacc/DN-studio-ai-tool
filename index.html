import React, { useEffect, useMemo, useRef, useState, useCallback } from 'react';
import { Clock, Download, FileText, Image as ImageIcon, Sparkles, X, RotateCw, Loader2, Volume2, Copy, Zap as ZapIcon, Settings, BrainCircuit, Users, CheckCircle, Save, TrendingUp, Cpu, List, Map, Lock, ClipboardCheck, BookOpen, Layers, Video } from 'lucide-react';

// --- Global Constants and Helper Functions ---

const cn = (...a) => a.filter(Boolean).join(' ');

// List of available TTS voices
const TTS_VOICES = [
    { name: 'Kore (Firm Narrator)', voiceName: 'Kore', description: 'Firm, clear, suitable for dramatic or professional narration.' },
    { name: 'Charon (Deep Informant)', voiceName: 'Charon', description: 'Deep, informative, suitable for solemn or documentary style.' },
    { name: 'Puck (Upbeat)', voiceName: 'Puck', description: 'Upbeat, friendly, suitable for trailers or energetic delivery.' },
    { name: 'Zephyr (Bright)', voiceName: 'Zephyr', description: 'Bright, smooth, suitable for professional and clean audio.' },
];

// List of available physical branding assets
const BRANDING_ASSETS = [
    'cup_etched', 'binder_emboss', 'glass_frosted', 'laptop_sticker', 'desk_nameplate'
];

// BRANDING ARCHITECT JSON SCHEMA
const BRANDING_SCHEMA = {
    type: 'ARRAY',
    items: {
        type: 'OBJECT',
        properties: {
            sceneHeader: { type: 'STRING' },
            scene_prompt_addition: { type: 'STRING', description: 'The concise, cinematic prompt addition detailing the physical prop inclusion. Must be a visual description only.' },
            brand_assets: {
                type: 'ARRAY',
                description: '1 to 2 assets chosen from the approved list with technical details.',
                items: {
                    type: 'OBJECT',
                    properties: {
                        asset_name: { type: 'STRING', enum: BRANDING_ASSETS },
                        placement: { type: 'STRING', description: 'e.g., On the main character\'s desk, near the camera.' },
                        material_finish: { type: 'STRING', description: 'e.g., Brushed aluminum, glossy plastic, frosted glass.' },
                        continuity_notes: { type: 'STRING', description: 'Notes on camera angle, movement, or consistency (e.g., Must remain in foreground 3/4 frame; Logo visible for 1s only).' }
                    },
                    required: ['asset_name', 'placement', 'material_finish', 'continuity_notes']
                }
            },
            safety_checks: { type: 'STRING', description: 'Confirmation that all safety checks (no readable text, screens off/blurred, logo size < 3%) are met.' }
        },
        required: ['sceneHeader', 'scene_prompt_addition', 'brand_assets', 'safety_checks']
    }
};

// VIRAL ARCHITECT JSON SCHEMA (Updated for Veo 3)
const VIRAL_SCHEMA = {
    type: 'ARRAY',
    items: {
        type: 'OBJECT',
        properties: {
            concept_title: { type: 'STRING' },
            genre: { type: 'STRING', enum: ['Comedy', 'Action', 'Pure Chaos', 'Informative', 'ASMR', 'Thriller', 'Dance', 'Emotional'] },
            eight_second_script: { type: 'STRING', description: 'A short script or breakdown of the 8-second video' },
            first_frame_prompt: { type: 'STRING', description: 'Hyper-detailed cinematic image prompt for the starting frame' },
            veo3_prompt: { type: 'STRING', description: 'The optimized Veo 3 image-to-video prompt based on the first frame and concept.' }
        },
        required: ['concept_title', 'genre', 'eight_second_script', 'first_frame_prompt', 'veo3_prompt']
    }
};

// 1. Audio Engine
const AudioEngine = {
    ctx: null,
    init() {
        if (this.ctx) return;
        try { this.ctx = new (window.AudioContext || window.webkitAudioContext)(); } catch {}
    },
    play(type) {
        if (!this.ctx) return;
        const o = this.ctx.createOscillator(), g = this.ctx.createGain();
        o.connect(g); g.connect(this.ctx.destination);
        g.gain.setValueAtTime(0, this.ctx.currentTime);

        if (type === 'click') {
            o.type='sine'; o.frequency.setValueAtTime(800,this.ctx.currentTime); g.gain.linearRampToValueAtTime(0.1,this.ctx.currentTime+0.01);
            o.frequency.exponentialRampToValueAtTime(450,this.ctx.currentTime+0.08); g.gain.exponentialRampToValueAtTime(1e-4,this.ctx.currentTime +0.09);
        } else if (type === 'success') {
            o.type='sine'; o.frequency.setValueAtTime(700, this.ctx.currentTime); g.gain.linearRampToValueAtTime(0.15,this.ctx.currentTime+0.01);
            o.frequency.exponentialRampToValueAtTime(1400,this.ctx.currentTime+0.1); g.gain.exponentialRampToValueAtTime (1e-4,this.ctx.currentTime +0.1);
        } else if (type === 'error') {
            o.type='square'; o.frequency.setValueAtTime(300,this.ctx.currentTime); g.gain.linearRampToValueAtTime(0.15,this.ctx.currentTime+0.01);
            o.frequency.exponentialRampToValueAtTime(150,this.ctx.currentTime +0.15); g.gain.exponentialRampToValueAtTime(1e-4,this.ctx.currentTime +0.15);
        }
        o.start(this.ctx.currentTime); o.stop(this.ctx.currentTime + 0.16);
    }
};

// --- Utility Functions ---

function base64ToArrayBuffer(base64) {
    const binaryString = atob(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
        bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
}

function pcmToWav(pcm16, sampleRate = 24000) {
    const numChannels = 1;
    const numSamples = pcm16.length;
    const byteRate = sampleRate * numChannels * 2;
    const blockAlign = numChannels * 2;
    const dataSize = numSamples * numChannels * 2;
    const buffer = new ArrayBuffer(44 + dataSize);
    const view = new DataView(buffer);

    function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }

    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + dataSize, true);
    writeString(view, 8, 'WAVE');
    view.setUint32(12, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, byteRate, true);
    view.setUint16(32, blockAlign, true);
    view.setUint16(34, 16, true);
    writeString(view, 36, 'data');
    view.setUint32(40, dataSize, true);

    let offset = 44;
    for (let i = 0; i < numSamples; i++, offset += 2) {
        view.setInt16(offset, pcm16[i], true);
    }

    return new Blob([view], { type: 'audio/wav' });
}

// 2. IndexedDB Helpers
const idb = (() => {
    let dbPromise = null;

    function getDB() {
        if (!('indexedDB' in window)) return null;
        if (!dbPromise) {
            dbPromise = new Promise((resolve, reject) => {
                const req = indexedDB.open('dn-ai-pro-apex-db-v3', 3);
                req.onupgradeneeded = (e) => {
                    const db = e.target.result;
                    if (!db.objectStoreNames.contains('history')) db.createObjectStore('history', { keyPath: 'timestamp' });
                    if (!db.objectStoreNames.contains('config')) db.createObjectStore('config', { keyPath: 'key' });
                };
                req.onsuccess = () => resolve(req.result);
                req.onerror = () => reject(req.error);
            });
        }
        return dbPromise;
    }

    return {
        async getHistory() {
            const db = await getDB();
            if (!db) return [];
            return new Promise((res, rej) => {
                const r = db.transaction('history', 'readonly').objectStore('history').getAll();
                r.onsuccess = () => res(r.result.sort((a,b) => b.timestamp - a.timestamp));
                r.onerror = () => rej(r.error);
            });
        },
        async addHistory(item) {
            const db = await getDB();
            if (!db) return false;
            return new Promise((res, rej) => {
                const t = db.transaction('history', 'readwrite');
                t.objectStore('history').put(item);
                t.oncomplete = () => res(true);
                t.onerror = () => rej(t.error);
            });
        },
        async getConfig(key) {
            const db = await getDB();
            if (!db) return null;
            return new Promise((res, rej) => {
                const r = db.transaction('config', 'readonly').objectStore('config').get(key);
                r.onsuccess = () => res(r.result ? r.result.value : null);
                r.onerror = () => rej(r.error);
            });
        },
        async setConfig(key, value) {
            const db = await getDB();
            if (!db) return false;
            return new Promise((res, rej) => {
                const t = db.transaction('config', 'readwrite');
                t.objectStore('config').put({ key, value });
                t.oncomplete = () => res(true);
                t.onerror = () => rej(t.error);
            });
        }
    };
})();

// 3. Task Queue
class TaskQueue {
    running = 0;
    q = [];
    max;
    onComplete = () => {};

    constructor(max = 3) { this.max = max; }
    setMax(n) { this.max = Math.max(1, n); this.tick(); }
    push(task) { this.q.push(task); this.tick(); }
    clear() { this.q.length = 0; this.onComplete(); }

    async tick() {
        if (this.running === 0 && this.q.length === 0) { this.onComplete(); return; }
        while (this.running < this.max && this.q.length > 0) {
            const t = this.q.shift();
            this.running++;
            t().finally(() => { this.running--; this.tick(); });
        }
    }
}

// 4. API Client with Exponential Backoff
async function safeFetchWithRetry(url, options, maxRetries, localApiKey) {
    const apiKey = localApiKey || "";
    const fullUrl = `${url}?key=${apiKey}`;

    for (let attempt = 0; attempt <= maxRetries; attempt++) {
        try {
            if (attempt > 0) {
                const delay = 1500 * Math.pow(2, attempt - 1);
                await new Promise(r => setTimeout(r, delay));
            }

            const response = await fetch(fullUrl, options);
            const json = await response.json();

            if (!response.ok) {
                const errorMessage = json.error?.message || json.error || `API error (${response.status}): ${JSON.stringify(json)}`;
                throw new Error(errorMessage);
            }

            return json; // Success
        } catch (e) {
            if (attempt === maxRetries) {
                throw e;
            }
        }
    }
}

async function callText(parts, system, jsonSchema, retryCount, apiKey, tools) {
    const model = 'gemini-2.5-flash-preview-05-20';

    let responseMimeType = undefined;
    if (jsonSchema) {
        responseMimeType = 'application/json';
    }

    const body = {
        contents: [{ parts }],
        systemInstruction: system ? { parts: [{ text: system }] } : undefined,
        generationConfig: jsonSchema ? { responseMimeType: responseMimeType, responseSchema: jsonSchema } : undefined,
        tools: tools,
    };

    const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`;

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 60000);

    try {
        const json = await safeFetchWithRetry(url, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(body),
            signal: controller.signal
        }, retryCount, apiKey);

        clearTimeout(timeoutId);

        const candidate = json.candidates?.[0];
        const text = candidate?.content?.parts?.[0]?.text;

        if (!text) {
             throw new Error('API returned no content. Response was incomplete or empty.');
        }

        return { text, sources: [] };

    } catch (e) {
        if (e.name === 'AbortError') {
             throw new Error('Multimodal call timed out after 60 seconds. File may be too large or complex.');
        }
        throw e;
    }
}

async function callImage(promptText, ref, retryCount, apiKey) {
    const model = 'gemini-2.5-flash-image-preview';
    const parts = [{ text: promptText }];

    if (ref && ref.startsWith('data:')) {
        const [meta, b64] = ref.split(',');
        const mimeType = meta.split(':')[1].split(';')[0] || 'image/jpeg';
        parts.push({ inlineData: { mimeType: mimeType, data: b64 } });
    }

    const body = {
        contents: [{ parts }],
        generationConfig: { responseModalities: ['IMAGE'] }
    };

    const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`;

    const json = await safeFetchWithRetry(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body)
    }, retryCount, apiKey);

    const base64 = json.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;

    if (!base64) throw new Error('Image API returned no image data.');

    return `data:image/png;base64,${base64}`;
}

async function callTTS(text, voice, retryCount, apiKey) {
    const model = 'gemini-2.5-flash-preview-tts';

    const body = {
        contents: [{ parts: [{ text: text }] }],
        generationConfig: {
            responseModalities: ["AUDIO"],
            speechConfig: {
                voiceConfig: {
                    prebuiltVoiceConfig: { voiceName: voice }
                }
            }
        },
        model: model
    };

    const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`;

    const json = await safeFetchWithRetry(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body)
    }, retryCount, apiKey);

    const part = json.candidates?.[0]?.content?.parts?.[0];
    const audioData = part?.inlineData?.data;
    const mimeType = part?.inlineData?.mimeType;

    if (!audioData || !mimeType) throw new Error('TTS API returned no audio data.');

    const rateMatch = mimeType.match(/rate=(\d+)/);
    const sampleRate = rateMatch ? parseInt(rateMatch[1], 10) : 24000;

    const pcmData = base64ToArrayBuffer(audioData);
    const pcm16 = new Int16Array(pcmData);
    const wavBlob = pcmToWav(pcm16, sampleRate);

    return URL.createObjectURL(wavBlob);
}


// --- Main Application Component ---

const fileToBase64 = (file) => new Promise((res, rej) => {
    const r = new FileReader();
    r.onload = () => res(String(r.result));
    r.onerror = rej;
    r.readAsDataURL(file);
});

export default function App() {
    const [visualStyle, setVisualStyle] = useState('Cinematic Photorealistic');
    const [narrative, setNarrative] = useState('A lone astronaut, EVA ROSTOVA, discovers a glowing alien artifact on Mars. It pulses with light, drawing her closer. She touches it, and the Martian landscape warps into a lush, alien jungle.');
    const [refImg, setRefImg] = useState(null);
    const [editRefImg, setEditRefImg] = useState(null);
    const [charLock, setCharLock] = useState(true);
    const [predicted, setPredicted] = useState(null);
    const [scenes, setScenes] = useState([]);
    const [busy, setBusy] = useState(false);
    const [status, setStatus] = useState('System Initialized. Ready for Quantum Processing.');
    const [err, setErr] = useState(null);
    const [showSettings, setShowSettings] = useState(false);
    const [showHistoryModal, setShowHistoryModal] = useState(false);
    const [historyItems, setHistoryItems] = useState([]);
    const [editingScene, setEditingScene] = useState(null);
    const [editPrompt, setEditPrompt] = useState('');
    const [isEditing, setIsEditing] = useState(false);
    const [creditsUsed, setCreditsUsed] = useState(0.00);
    const [characterSheet, setCharacterSheet] = useState(null);
    const [directorsVision, setDirectorsVision] = useState(null);
    const [showVisionModal, setShowVisionModal] = useState(false);
    const [scriptFile, setScriptFile] = useState(null);
    const [apiKey, setApiKey] = useState('');
    const [ttsLoading, setTtsLoading] = useState(false);
    const [ttsAudioUrl, setTtsAudioUrl] = useState(null);
    const [selectedVoice, setSelectedVoice] = useState(TTS_VOICES[0].voiceName);
    const [autoExecute, setAutoExecute] = useState(false);
    
    // BRANDING STATE
    const [isBrandingMode, setIsBrandingMode] = useState(false);
    const [brandingOutput, setBrandingOutput] = useState(null);
    const [showBrandingModal, setShowBrandingModal] = useState(false);
    const [logoRefImg, setLogoRefImg] = useState(null);
    const [logoDescription, setLogoDescription] = useState(null);

    // MATRIX TOOL STATE
    const [showComplexityModal, setShowComplexityModal] = useState(false);
    const [showFlowModal, setShowFlowModal] = useState(false);
    const [showAssetDescModal, setShowAssetDescModal] = useState(false);
    const [complexityReport, setComplexityReport] = useState(null);
    const [flowReport, setFlowReport] = useState(null);
    const [assetDescPrompt, setAssetDescPrompt] = useState('');
    const [assetDescReport, setAssetDescReport] = useState(null);
    const [showPurityModal, setShowPurityModal] = useState(false);
    const [purityReport, setPurityReport] = useState(null);
    
    // VIRAL VIDEO ARCHITECT STATE (Updated)
    const [showViralModal, setShowViralModal] = useState(false);
    const [viralIdeas, setViralIdeas] = useState(null);
    const [viralMode, setViralMode] = useState('general');
    const [viralLoading, setViralLoading] = useState(false);
    const [viralBrandName, setViralBrandName] = useState('');
    const [viralProduct, setViralProduct] = useState('');


    // FIXED CONSTANTS
    const FIXED_ASPECT_RATIO = '16:9';
    const aspectRatioClass = 'aspect-[16/9]';


    const maxConcurrent = 1;
    const retryCount = 2;
    const queueRef = useRef(new TaskQueue(maxConcurrent));
    const audioRef = useRef(null);

    // --- Initialization and Persistence ---
    useEffect(() => {
        AudioEngine.init();
        Promise.all([
            idb.getHistory().then(setHistoryItems).catch(() => console.error("Failed to load history.")),
            idb.getConfig('apiKey').then(key => setApiKey(key || '')),
            idb.getConfig('logoRefImg').then(img => setLogoRefImg(img || null)),
        ]).finally(() => {
            setTimeout(() => {
                setStatus('System Initialized. Welcome, Director.');
            }, 1500);
        });
    }, []);

    // Auto-save API Key and Logo Ref when updated
    useEffect(() => {
        if (apiKey) idb.setConfig('apiKey', apiKey).catch(e => console.error("Failed to save API key:", e));
    }, [apiKey]);
    
    useEffect(() => {
        if (logoRefImg !== null) {
            idb.setConfig('logoRefImg', logoRefImg).catch(e => console.error("Failed to save logo ref:", e));
            setLogoDescription(null);
        }
    }, [logoRefImg]);
    
    // Hook for queue completion logic
    useEffect(() => {
        queueRef.current.onComplete = () => {
            setTimeout(() => {
                setBusy(false);
                setStatus('Frame Synthesis complete. All tasks terminated.');
                setScenes(current => {
                    if (current.length > 0 && current.every(s => ['success', 'error'].includes(s.status))) {
                        const historyEntry = {
                            timestamp: Date.now(),
                            scenes: current.map(s => ({...s, status: s.status, prompt: s.prompt, image: s.image})),
                            cost: creditsUsed,
                            vision: directorsVision,
                            branding: brandingOutput,
                            config: { visualStyle, aspectRatio: FIXED_ASPECT_RATIO, scriptFile, isBrandingMode, logoRefImg }
                        };
                        idb.addHistory(historyEntry)
                           .then(() => idb.getHistory().then(setHistoryItems))
                           .catch(() => console.error("Failed to save history"));
                        return current;
                    }
                    return current;
                });
            }, 400);
        };
    }, [creditsUsed, directorsVision, visualStyle, scriptFile, isBrandingMode, brandingOutput, logoRefImg]);


    const incrementCredits = useCallback(() => setCreditsUsed(c => parseFloat((c + 0.10).toFixed(2))), []);

    const loadHistoryItem = useCallback((item) => {
        setNarrative(item.vision?.enhanced_script || 'Script reloaded from history.');
        setDirectorsVision(item.vision);
        setScenes(item.scenes);
        setPredicted(null);
        setCreditsUsed(item.cost);
        setVisualStyle(item.config.visualStyle);
        setScriptFile(item.config.scriptFile || null);
        setCharacterSheet(item.vision?.character_sheet || null);
        setBrandingOutput(item.branding || null);
        setIsBrandingMode(item.config.isBrandingMode || false);
        setLogoRefImg(item.config.logoRefImg || null);
        setShowHistoryModal(false);
        setStatus('Project state reloaded successfully.');
        AudioEngine.play('success');
    }, []);

    // Save current project state manually
    const handleSaveState = useCallback(async () => {
        AudioEngine.play('success');
        setStatus('Saving current project state...');
        try {
            const historyEntry = {
                timestamp: Date.now(),
                scenes: scenes.map(s => ({...s, status: s.status, prompt: s.prompt, image: s.image})),
                cost: creditsUsed,
                vision: directorsVision,
                branding: brandingOutput,
                config: { visualStyle, aspectRatio: FIXED_ASPECT_RATIO, scriptFile, isBrandingMode, logoRefImg }
            };
            await idb.addHistory(historyEntry);
            await idb.getHistory().then(setHistoryItems);
            setStatus('Project state saved successfully.');
        } catch (e) {
            setErr(`Save Error: ${String(e.message)}`);
            setStatus('Failed to save project state.');
            AudioEngine.play('error');
        }
    }, [scenes, creditsUsed, directorsVision, brandingOutput, visualStyle, scriptFile, isBrandingMode, logoRefImg]);

    // Download Function for TTS
    const handleDownloadAudio = useCallback(() => {
        if (!ttsAudioUrl) return;
        AudioEngine.play('click');
        const a = document.createElement('a');
        a.href = ttsAudioUrl;
        a.download = `DN_AI_Voiceover_${Date.now()}.wav`;
        a.click();
        setTimeout(() => URL.revokeObjectURL(ttsAudioUrl), 100);
    }, [ttsAudioUrl]);

    // --- TTS Logic (AI Voiceover Creator) ---
    const handleTtsCreation = useCallback(async () => {
        AudioEngine.play('click');
        if (!narrative || ttsLoading) return;

        setTtsLoading(true);
        setTtsAudioUrl(null);
        setStatus('Generating AI Voiceover Preview...');
        setErr(null);

        try {
            const analysisPrompt = `Analyze the tone of the user's script (first 300 characters: "${narrative.slice(0, 300)}...") and create a precise, natural language instruction for a professional voice actor. This instruction MUST be the single sentence starting with "Say the following script segment with a..." specifying style, tone, pace, and emotional feeling, tailored to the selected voice's characteristics. DO NOT include the script segment itself in this response.`;
            
            const { text: styleInstruction } = await callText([{ text: analysisPrompt }], "You are a professional film director providing voiceover guidance.", undefined, retryCount, apiKey);

            const ttsPrompt = `${styleInstruction} for the following text: "${narrative.slice(0, 300)}..."`;

            const audioUrl = await callTTS(ttsPrompt, selectedVoice, retryCount, apiKey);
            
            if (audioRef.current) {
                audioRef.current.src = audioUrl;
                audioRef.current.play();
            }
            
            setTtsAudioUrl(audioUrl);
            setStatus('AI Voiceover CREATOR output ready and playing.');
            AudioEngine.play('success');
            
        } catch (e) {
            setErr(`TTS Error: ${String(e.message)}`);
            setStatus('AI Voiceover generation failed.');
            AudioEngine.play('error');
        } finally {
            setTtsLoading(false);
        }
    }, [narrative, ttsLoading, selectedVoice, apiKey, retryCount, audioRef]);


    // Function to extract text from multimodal files (PDF, DOCX)
    async function extractScriptFromDocument(file) {
        setStatus(`Analyzing ${file.name} (Initiating deep-scan sequence, $0.05 charge)...`);

        const MAX_FILE_SIZE = 20 * 1024 * 1024;
        if (file.size > MAX_FILE_SIZE) {
             throw new Error("File size exceeds 20MB limit for deep-scan analysis.");
        }

        const mimeType = file.type;
        let base64Data;
        try {
            const dataUrl = await fileToBase64(file);
            base64Data = dataUrl.split(',')[1];
        } catch (e) {
            throw new Error(`Failed to read file contents: ${e.message}`);
        }

        const sys = "You are an expert film industry document processor. It is CRITICAL that you preserve all original formatting, including SCENE HEADERS (EXT./INT.), CHARACTER NAMES, DIALOGUE blocks, and ACTION lines. Your output MUST be the raw, formatted script text only.";

        const parts = [{ text: "Extract the full formatted script from this document." }, { inlineData: { mimeType, data: base64Data } }];

        try {
            const { text } = await callText(parts, sys, undefined, retryCount, apiKey);
            return text;
        } catch (e) {
            console.error("Gemini Document Extraction Failed:", e);
            throw new Error(`Multimodal analysis failed. Error: ${String(e.message)}`);
        }
    }

    async function handleScriptUpload(e) {
        const file = e.target.files?.[0];
        if (!file) return;

        setScriptFile(file.name);
        setBusy(true);
        setErr(null);

        try {
            let extractedContent = '';

            if (file.type.startsWith('text/')) {
                extractedContent = await file.text();
                if (extractedContent.length === 0) {
                     throw new Error("Text file is empty.");
                }
            }
            else if (['application/pdf', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'].includes(file.type)) {
                extractedContent = await extractScriptFromDocument(file);
                setCreditsUsed(c => parseFloat((c + 0.05).toFixed(2)));
            } else {
                throw new Error(`Unsupported file type: ${file.type}. Please use .txt, .pdf, or .docx.`);
            }

            setNarrative(extractedContent);
            setStatus(`Script data stream initialized from ${file.name}.`);
            AudioEngine.play('success');

        } catch (error) {
            const displayError = String(error.message || "Unknown file processing error.");
            setErr(displayError);
            setStatus('Error: Failed to process data stream.');
            AudioEngine.play('error');
        } finally {
            setBusy(false);
            e.target.value = null;
        }
    }


    // AI Director: Core Vision Matrix + Auto Enhancement
    async function runAiDirector() {
        AudioEngine.play('click');
        setBusy(true);
        setErr(null);
        setStatus('AI Director: Initiating Deep Script Analysis and Cinematic Enhancement...');
        setDirectorsVision(null);
        setCharacterSheet(null);
        setPredicted(null);
        setScenes([]);
        setBrandingOutput(null);
        setComplexityReport(null);
        setFlowReport(null);
        setAssetDescReport(null);
        setPurityReport(null);

        try {
            let charSheet = null;
            if (refImg && charLock) {
                setStatus("Analyzing character reference image using multi-modal sensor...");
                const sysChar = "You are a forensic artist. Describe the person in this image in extreme detail for a character sheet. Respond in JSON with a single key 'description'.";
                const schemaChar = { type: 'OBJECT', properties: { description: { type: 'STRING' } }, required: ['description'] };
                const partsChar = [{ text: 'Describe this person.' }, { inlineData: { mimeType: 'image/jpeg', data: refImg.split(',')[1] } }];

                const { text: charResult } = await callText(partsChar, sysChar, schemaChar, retryCount, apiKey);
                charSheet = JSON.parse(charResult).description;
                setCharacterSheet(charSheet);
            }

            setStatus("Developing Director's Vision Matrix and Auto-Enhancing Script...");
            const enhancementInstruction = "URGENT: After defining the core vision, immediately rewrite the provided script. You are an expert Hollywood script doctor and cinematographer. Rewrite the script's action lines to include explicit, cinematic shot information and descriptive camera movements (e.g., CLOSE UP on the astronaut's gloved hand, CRANE SHOT revealing the Martian vista, SLOW PUSH IN on the artifact). DO NOT change any dialogue, character names, or scene headings (EXT./INT.).";
            
            const sysVision = `You are an acclaimed film director and story analyst. Analyze this script and perform the Cinematic Enhancement.
${enhancementInstruction}
MANDATORY OUTPUT FIELDS (Respond STRICTLY in JSON only):
1. main_goal: The single, overriding narrative objective or theme the video must convey.
2. core_theme: The central idea or message of the script.
3. visual_tone: The overall aesthetic and emotional mood (e.g., Gritty, Luminous, Oppressive).
4. cinematography_style: Technical camera style (e.g., Handheld Documentary, Symmetrical Wide Shots, Dutch Angles).
5. enhanced_script: The final, rewritten, cinematically enhanced script text.
`;
            const schemaVision = {
                type: 'OBJECT',
                properties: {
                    main_goal: { type: 'STRING' },
                    core_theme: { type: 'STRING' },
                    visual_tone: { type: 'STRING' },
                    cinematography_style: { type: 'STRING' },
                    enhanced_script: { type: 'STRING' }
                },
                required: ['main_goal', 'core_theme', 'visual_tone', 'cinematography_style', 'enhanced_script']
            };

            const { text: visionResult } = await callText([{ text: narrative }], sysVision, schemaVision, retryCount, apiKey);
            const vision = JSON.parse(visionResult);
            if (charSheet) vision.character_sheet = charSheet;

            setNarrative(vision.enhanced_script);
            setDirectorsVision(vision); 
            
            setShowVisionModal(true);
            setStatus("Director's Vision and Enhanced Script complete. Awaiting user approval to proceed with scene segmentation.");
            AudioEngine.play('success');

        } catch (e) {
            setErr(String(e.message || e));
            setStatus('AI Director analysis failed. Review script input.');
            AudioEngine.play('error');
        } finally {
            setBusy(false);
        }
    }

    // Scene Segmentation and Prompt Generation
    async function generateScenesFromVision() {
        AudioEngine.play('click');
        setShowVisionModal(false);
        setBusy(true);
        setErr(null);
        setStatus('Generating scene prompts based on Vision and Style Matrix...');
        try {
            if (!directorsVision) throw new Error("Director's Vision Matrix is missing.");

            const visionContext = `MAIN GOAL: ${directorsVision.main_goal}. Theme: ${directorsVision.core_theme}, Tone: ${directorsVision.visual_tone}, Cinematography: ${directorsVision.cinematography_style}${directorsVision.character_sheet ? ` Main Character (${directorsVision.main_character}) Appearance: ${directorsVision.character_sheet}` : ''}`;

            const schema = {
                type: 'ARRAY',
                items: {
                    type: 'OBJECT',
                    properties: { sceneHeader: { type: 'STRING' }, prompt: { type: 'STRING' } },
                    required: ['sceneHeader', 'prompt']
                }
            };

            const sys = `You are a storyboard artist. Use the ENHANCED SCRIPT (which contains shot descriptions) and strictly adhere to the DIRECTOR'S VISION to create production-grade image prompts. The vision is paramount. If the main character is mentioned, their appearance MUST match the character sheet. URGENT AND MANDATORY: All images must be rendered in a "${visualStyle}" style and have an exact aspect ratio of "${FIXED_ASPECT_RATIO}". Respond in JSON only.`;

            const { text } = await callText([{ text: `Enhanced Script: \n\n${directorsVision.enhanced_script}\n\n${visionContext}` }], sys, schema, retryCount, apiKey);

            const parsed = JSON.parse(text);

            setPredicted(parsed.map((s, i) => ({ id: i, ...s })));
            setStatus(`Generated ${parsed.length} visual segment prompts. Ready for Frame Synthesis.`);

            if (autoExecute) {
                setTimeout(() => {
                    const initialScenes = parsed.map((s, i) => ({ id: i, ...s, status: 'queued', image: null, error: null }));
                    setCreditsUsed(c => parseFloat((c + initialScenes.length * 0.10).toFixed(2)));
                    setScenes(initialScenes);
                    generateAllImagesContinuity(initialScenes);
                }, 100);
            }

            AudioEngine.play('success');

        } catch (e) {
            setErr(String(e.message || e));
            setStatus('Error generating visual segment prompts.');
            AudioEngine.play('error');
        } finally {
            if (!autoExecute) setBusy(false);
        }
    }
    
    // --- FIX: Scene Regeneration ---
    function regenerateScene(sceneId) {
        AudioEngine.play('click');
        const sceneIndex = scenes.findIndex(x => x.id === sceneId);
        if (sceneIndex === -1) return;

        setBusy(true);
        setStatus(`Retrying scene ${sceneIndex + 1} generation...`);

        // 1. Mark scene as queued immediately
        setScenes(prev => prev.map(scene =>
            scene.id === sceneId ? { ...scene, status: 'queued', error: null } : scene
        ));
        
        // 2. Determine the continuity reference for the retry
        let refForRetry = (charLock && refImg) ? refImg : null;
        if (sceneIndex > 0) {
            const prevScene = scenes[sceneIndex - 1];
            if (prevScene.image && prevScene.status === 'success') {
                refForRetry = prevScene.image;
            }
        }
        
        // 3. Create a disposable copy of the scenes array for the task factory closure
        const currentSceneDataCopy = [...scenes]; 
        
        // 4. Push the task to the queue
        queueRef.current.push(() => runGenerationTaskContinuity(sceneIndex, refForRetry, currentSceneDataCopy));
    }


    // Sequential Generation Task that feeds its output to the next scene's input
    const runGenerationTaskContinuity = useCallback(async (sceneIndex, initialRef, sceneDataArray) => {

        const updateScene = (patch) => {
            setScenes(prev => {
                const newScenes = prev.map(s => (s.id === sceneDataArray[sceneIndex].id ? { ...s, ...patch } : s));
                if (patch.image) {
                    sceneDataArray[sceneIndex].image = patch.image;
                }
                return newScenes;
            });
        };

        let currentRef = initialRef;
        if (sceneIndex > 0) {
            const prevScene = sceneDataArray[sceneIndex - 1];
            if (prevScene.image && prevScene.status === 'success') {
                currentRef = prevScene.image;
            } else if (charLock && refImg) {
                currentRef = refImg;
            } else {
                currentRef = null;
            }
        } else if (!charLock) {
            currentRef = null;
        }

        let attempt = 0, ok = false, imageUrl = null, errorMsg = '';
        const sceneData = sceneDataArray[sceneIndex];

        let ultraRefinedPrompt = sceneData.prompt;

        try {
            updateScene({ status: 'optimizing' });

            // --- CRITICAL BRAND LOCK ENFORCEMENT ---
            const logoAnalysisContext = isBrandingMode && logoDescription 
                ? `| BRAND LOCK: Logo details - Color: ${logoDescription.color}, Shape: ${logoDescription.shape}, Materials: ${logoDescription.materials}. ENSURE THESE VISUAL TRAITS ARE REFLECTED IN THE PHYSICAL BRAND ASSETS.` 
                : '';
                
            const optimizationSys = `You are an AI Prompt Engineer. Synthesize a single, hyper-detailed, technical image generation prompt from the RAW SCENE PROMPT. The final prompt MUST strictly enforce the visual style, aspect ratio (${FIXED_ASPECT_RATIO}), character consistency, and ${isBrandingMode ? 'subtle brand placement' : 'narrative details'} derived from the context. Make the language descriptive and cinematic. DO NOT include any JSON, only the final prompt string.`;

            const optimizationContext = `RAW SCENE PROMPT: ${sceneData.prompt} | VISUAL STYLE: ${visualStyle} | CORE VIDEO GOAL: ${directorsVision?.main_goal || 'N/A'} | CINEMATIC VISION: ${JSON.stringify(directorsVision)} | CONTINUITY REF IMAGE USED: ${currentRef ? 'YES' : 'NO'}${logoAnalysisContext}`;

            const { text: refinedPrompt } = await callText([{ text: optimizationContext }], optimizationSys, undefined, retryCount, apiKey);

            // 3. BRANDING INTEGRATION (MANDATORY if enabled)
            const brandingData = brandingOutput ? brandingOutput.find(b => b.sceneHeader === sceneData.sceneHeader) : null;

            if (isBrandingMode && brandingData) {
                const brandAssets = brandingData.brand_assets.map(a => `${a.asset_name}: Placement: ${a.placement}, Material: ${a.material_finish}, Notes: ${a.continuity_notes}`).join('; ');
                
                const brandingInstruction = `[BRANDING INTEGRATION REQUIRED] Apply: ${brandingData.scene_prompt_addition}. Integrate these physical assets: (${brandAssets}). CRITICAL SAFETY CHECK: Screens OFF/BLURRED. No readable text. Logo area < 3% of frame. No digital glow/shadow on logo.`;

                ultraRefinedPrompt = `${brandingInstruction} [CINEMATIC FRAMING: HORIZONTAL WIDESCREEN 16x9 ASPECT RATIO, FILM STILL] ${refinedPrompt}`;
            } else {
                ultraRefinedPrompt = `[CINEMATIC FRAMING: HORIZONTAL WIDESCREEN 16x9 ASPECT RATIO, FILM STILL] ${refinedPrompt}`;
            }

            updateScene({ prompt: ultraRefinedPrompt, status: 'starting' });

        } catch (e) {
            console.warn("Prompt Optimization Failed, using original prompt:", e);
            setStatus(`Warning: Prompt optimization failed for Scene ${sceneIndex}. Using original prompt.`);
            ultraRefinedPrompt = `[CINEMATIC FRAMING: HORIZONTAL WIDESCREEN 16x9 ASPECT RATIO, FILM STILL] ${sceneData.prompt}`;
        }

        // 4. Start Image Generation Loop
        try {
            while (attempt <= retryCount && !ok) {
                attempt++;
                if (attempt > 1) incrementCredits();

                updateScene({ status: attempt > 1 ? `retrying ${attempt - 1}/${retryCount}` : 'generating' });

                try {
                    const img = await callImage(ultraRefinedPrompt, currentRef, 0, apiKey);
                    imageUrl = img;
                    ok = true;
                } catch (err) {
                    errorMsg = String(err.message || err);
                    if (attempt <= retryCount) await new Promise(r => setTimeout(r, 1500));
                }
            }

            const patch = { status: ok ? 'success' : 'error', image: imageUrl, error: ok ? null : errorMsg };
            updateScene(patch);
            AudioEngine.play(ok ? 'success' : 'error');

            if (!ok) throw new Error(errorMsg);

        } catch (err) {
            updateScene({ status: 'error', error: String(err.message || err) });
            AudioEngine.play('error');
            throw err;
        }
    }, [charLock, refImg, retryCount, visualStyle, apiKey, incrementCredits, directorsVision, FIXED_ASPECT_RATIO, isBrandingMode, brandingOutput, logoDescription]);

    const generateAllImagesContinuity = (initialScenes) => {
        setBusy(true);
        setStatus('Starting sequential continuity synthesis...');
        let sceneData = initialScenes;

        const createTask = (sceneIndex, continuityRef) => () => runGenerationTaskContinuity(sceneIndex, continuityRef, sceneData);

        const tasks = sceneData.map((scene, index) => {
            if (index === 0) {
                return createTask(index, (charLock && refImg) ? refImg : null);
            }
            return createTask(index, null);
        });

        tasks.forEach(task => queueRef.current.push(task));
    };

    function generateAllImages() {
        if (!predicted?.length) return;

        const initialScenes = predicted.map((s, i) => ({ ...s, status: 'queued', image: null, error: null, id: i }));

        setCreditsUsed(c => parseFloat((c + initialScenes.length * 0.10).toFixed(2)));
        setScenes(initialScenes);

        generateAllImagesContinuity(initialScenes);
    }
    
    // --- Image Editing ---
    async function handleEditImage() {
        AudioEngine.play('click');
        if (!editingScene || !editPrompt) return;
        setIsEditing(true);
        setErr(null);
        incrementCredits();
        
        const refForCall = editRefImg || editingScene.image;
        
        try {
            const logoContext = isBrandingMode && logoDescription 
                ? `Maintain the branding element described by: Color: ${logoDescription.color}, Shape: ${logoDescription.shape}, Materials: ${logoDescription.materials}.` 
                : '';
            
            const fullEditPrompt = `Based on the attached image, apply this change: ${editPrompt}. Maintain the visual style and aspect ratio. ${logoContext} CRITICAL: Do not add any text overlays.`;
            const newImageUrl = await callImage(fullEditPrompt, refForCall, retryCount, apiKey);

            setScenes(prev => prev.map(s => s.id === editingScene.id ? {
                ...s,
                image: newImageUrl,
                prompt: `${s.prompt}\n\n[USER EDIT: ${editPrompt}]`
            } : s));
            setEditingScene(null);
            setEditPrompt('');
            setEditRefImg(null);
            setStatus('Image edited successfully. New frame synthesized.');
            AudioEngine.play('success');
        } catch (e) {
            setErr(`Failed to edit image: ${String(e.message || e)}`);
            AudioEngine.play('error');
        } finally {
            setIsEditing(false);
        }
    }

    // --- MATRIX TOOL: Script Purity Filter (NEW) ---
    async function runScriptPurityFilter() {
        AudioEngine.play('click');
        if (!directorsVision?.enhanced_script) {
            setErr("Script Purity Filter requires the Director's Vision (with Enhanced Script) to be generated first.");
            return;
        }

        setBusy(true);
        setPurityReport(null);
        setErr(null);
        setStatus('Executing Purity Filter: Analyzing script structure, dialogue, and pacing...');

        try {
            const sys = `You are a script purity expert and dialogue coach. Analyze the provided script for structural weaknesses, clichés, weak dialogue, and pacing issues. Provide actionable feedback in a structured Markdown report. Identify 3-5 specific points of weakness and provide a clear, concise suggestion for improvement for each. Output must be a single Markdown document (no JSON).`;

            const context = `Director's Vision: ${JSON.stringify(directorsVision)}`;
            const parts = [{ text: `Enhanced Script for structural and purity analysis: ${directorsVision.enhanced_script}\n\n${context}` }];
            const { text: reportText } = await callText(parts, sys, undefined, retryCount, apiKey);

            setPurityReport(reportText);
            setShowPurityModal(true);
            setStatus('Script Purity Filter complete. Structural integrity report ready.');
            AudioEngine.play('success');
        } catch (e) {
            setErr(`Purity Filter Error: ${String(e.message)}`);
            setStatus('Script purity analysis failed.');
            AudioEngine.play('error');
        } finally {
            setBusy(false);
        }
    }

    // --- MATRIX TOOL: Scene Complexity Cipher ---
    async function runComplexityCipher() {
        AudioEngine.play('click');
        if (!directorsVision?.enhanced_script) {
            setErr("Complexity Cipher requires the Director's Vision (with Enhanced Script) to be generated first.");
            return;
        }

        setBusy(true);
        setComplexityReport(null);
        setErr(null);
        setStatus('Executing Complexity Cipher: Quantifying scene production costs...');

        try {
            const sys = `You are a Line Producer. Analyze the script and identify 4-6 scenes. For each scene, assign a complexity score (1-10, 10=Most Complex/Expensive) for VFX, Location, and Dialogue/Action. Output must be a JSON array of objects.`;

            const schema = {
                type: 'ARRAY',
                items: {
                    type: 'OBJECT',
                    properties: {
                        scene: { type: 'STRING', description: 'The scene header' },
                        vfx_complexity: { type: 'NUMBER', description: 'VFX Complexity score (1-10)' },
                        location_difficulty: { type: 'NUMBER', description: 'Location difficulty score (1-10)' },
                        action_density: { type: 'NUMBER', description: 'Dialogue/Action density score (1-10)' },
                        summary: { type: 'STRING', description: 'Brief explanation of complexity drivers' }
                    },
                    required: ['scene', 'vfx_complexity', 'location_difficulty', 'action_density', 'summary']
                }
            };

            const parts = [{ text: `Enhanced Script to analyze: ${directorsVision.enhanced_script}` }];
            const { text: reportJson } = await callText(parts, sys, schema, retryCount, apiKey);

            setComplexityReport(JSON.parse(reportJson));
            setShowComplexityModal(true);
            setStatus('Scene Complexity Cipher complete. Budget metrics available.');
            AudioEngine.play('success');
        } catch (e) {
            setErr(`Complexity Cipher Error: ${String(e.message)}`);
            setStatus('Complexity cipher failed.');
            AudioEngine.play('error');
        } finally {
            setBusy(false);
        }
    }
    
    // --- MATRIX TOOL: Narrative Flow Auditor ---
    async function runFlowAuditor() {
        AudioEngine.play('click');
        if (!directorsVision?.enhanced_script) {
            setErr("Narrative Flow Auditor requires the Director's Vision (with Enhanced Script) to be generated first.");
            return;
        }

        setBusy(true);
        setFlowReport(null);
        setErr(null);
        setStatus('Executing Narrative Flow Auditor: Checking scene transitions and arc integrity...');

        try {
            const sys = `You are a master story editor and dramaturg. Analyze the script focusing on the narrative continuity. Identify 4-6 key transitions/arcs. For each, describe the dramatic transition and assess its effectiveness, noting any logical jumps or pacing issues. Output should be a single Markdown document (no JSON).`;
            
            const context = `Director's Vision: ${JSON.stringify(directorsVision)}`;
            const parts = [{ text: `Enhanced Script for narrative flow audit: ${directorsVision.enhanced_script}\n\n${context}` }];
            const { text: reportText } = await callText(parts, sys, undefined, retryCount, apiKey);

            setFlowReport(reportText);
            setShowFlowModal(true);
            setStatus('Narrative Flow Auditor complete. Integrity report ready.');
            AudioEngine.play('success');
        } catch (e) {
            setErr(`Flow Auditor Error: ${String(e.message)}`);
            setStatus('Narrative flow audit failed.');
            AudioEngine.play('error');
        } finally {
            setBusy(false);
        }
    }

    // --- MATRIX TOOL: Visual Asset Descriptor ---
    async function runAssetDescriptor() {
        AudioEngine.play('click');
        if (!assetDescPrompt) {
            setErr("Visual Asset Descriptor requires a descriptive prompt (e.g., 'A tattered leather book with arcane symbols').");
            return;
        }

        setBusy(true);
        setAssetDescReport(null);
        setErr(null);
        setStatus('Executing Visual Asset Descriptor: Generating hyper-detailed specifications...');

        try {
            const sys = `You are a master conceptual designer. Take the user's simple request for a prop/asset and generate an extremely detailed, technical specification manifest suitable for a 3D modeler or prop fabricator. Focus on materials, texture, dimensions (relative or specific), wear/damage, and interaction properties. Output must be a single Markdown document (no JSON).`;
            
            const parts = [{ text: `Generate technical specs for this asset: ${assetDescPrompt}. Use the visual style: ${visualStyle}` }];
            const { text: reportText } = await callText(parts, sys, undefined, retryCount, apiKey);

            setAssetDescReport(reportText);
            setShowAssetDescModal(true);
            setStatus('Visual Asset Descriptor complete. Asset manifest generated.');
            AudioEngine.play('success');
        } catch (e) {
            setErr(`Asset Descriptor Error: ${String(e.message)}`);
            setStatus('Asset descriptor generation failed.');
            AudioEngine.play('error');
        } finally {
            setBusy(false);
        }
    }
    
    // --- Branding Architect ---
    async function runBrandingArchitect() {
        AudioEngine.play('click');
        if (!predicted?.length) {
            setErr("Branding Architect requires scene segmentation to be run first.");
            return;
        }
        if (isBrandingMode && !logoRefImg) {
            setErr("Branding Mode is ON. Please upload a Reference LOGO Image for analysis.");
            return;
        }

        setBusy(true);
        setBrandingOutput(null);
        setErr(null);
        
        try {
            let logoDesc = logoDescription;
            // 1. Analyze Logo Image if it hasn't been done yet
            if (logoRefImg && !logoDesc) {
                setStatus('Executing Logo Analysis: Determining color palette and geometry...');
                
                const sysLogo = "You are a Brand Analyst. Describe the provided logo image in terms of its main color palette (HEX or Name), geometric shape (e.g., simple geometric, complex emblem, stylized lettermark), and suggest ideal subtle material finishes (e.g., matte black vinyl, polished chrome, etched glass). Respond in JSON with keys: color, shape, materials. CRITICAL: Keep descriptions concise.";
                const schemaLogo = {
                    type: 'OBJECT',
                    properties: { color: { type: 'STRING' }, shape: { type: 'STRING' }, materials: { type: 'STRING' } },
                    required: ['color', 'shape', 'materials']
                };

                const [meta, b64] = logoRefImg.split(',');
                const mimeType = meta.split(':')[1].split(';')[0] || 'image/jpeg';
                const partsLogo = [{ text: "Analyze this logo image." }, { inlineData: { mimeType, data: b64 } }];

                const { text: logoResult } = await callText(partsLogo, sysLogo, schemaLogo, retryCount, apiKey);
                logoDesc = JSON.parse(logoResult);
                setLogoDescription(logoDesc);
            }
            
            setStatus('Generating optimal brand integration plan...');
            
            // 2. Generate Branding Plan using all context
            const logoContext = logoDesc ? `LOGO DETAILS: Color: ${logoDesc.color}, Shape: ${logoDesc.shape}, Ideal Materials: ${logoDesc.materials}.` : '';

            const sys = `You are the Brand Placement Director. ${logoContext} Your task is to integrate one or two subtle, realistic, and PHYSICAL brand assets into each scene using the available assets: [${BRANDING_ASSETS.join(', ')}].
The integration MUST be subtle, realistic, and physical (no overlay text).
For each scene, generate a detailed integration plan, tailoring the material_finish based on the LOGO DETAILS provided.
SAFETY CHECKS ARE PARAMOUNT. Respond STRICTLY in JSON array format using the specified schema.`;

            const sceneData = predicted.map(s => ({ sceneHeader: s.sceneHeader, basePrompt: s.prompt }));
            const context = `Director's Vision: ${JSON.stringify(directorsVision)}`;
            
            const parts = [{ text: `Scene Prompts to integrate branding into: ${JSON.stringify(sceneData)}\n\n${context}` }];

            const { text: generatedJson } = await callText(parts, sys, BRANDING_SCHEMA, retryCount, apiKey);

            const parsedBranding = JSON.parse(generatedJson);
            setBrandingOutput(parsedBranding);
            setShowBrandingModal(true);
            setStatus('Branding Architect complete. Integration plan ready.');
            AudioEngine.play('success');

        } catch (e) {
            setErr(`Branding Architect Error: ${String(e.message)}`);
            setStatus('Branding integration failed.');
            AudioEngine.play('error');
        } finally {
            setBusy(false);
        }
    }

    // --- MATRIX TOOL: Viral Video Architect ---
    async function runViralVideoArchitect() {
        AudioEngine.play('click');
        setViralLoading(true);
        setViralIdeas(null);
        setErr(null);
        setStatus(`Viral Architect: Analyzing current internet trends for 10 unique ${viralMode === 'ads' ? 'Ad' : 'General'} concepts...`);

        try {
            
            const brandInfo = (viralBrandName || viralProduct) 
                ? `Focus on the brand: "${viralBrandName}" and the product/service: "${viralProduct}".`
                : 'Generate arbitrary/random brand/product ideas.';
            
            const modePrompt = viralMode === 'ads' 
                ? `Generate 10 unique, bizarre, and highly engaging 8-second video AD concepts for the provided brand/product. ${brandInfo} The ad must be designed to go viral and feel culturally relevant. IMPORTANT: Ensure the first frame prompt includes a clear visual of the product/brand.`
                : "Generate 10 unique, strange, and highly engaging 8-second video concepts based on current, abstract internet trends. Focus on maximum shareability and surprise. The concept must be self-contained in 8 seconds. Ignore the brand/product fields.";

            // STEP 1: Perform Deep Search and generate *raw text* output
            const sysSearch = `You are a viral content consultant and trend forecaster for short-form video platforms. Use deep, real-time trend analysis (Google Search tool is enabled). Your task is to generate exactly 10 concepts. For each concept, list the title, genre (choose from Comedy, Action, Pure Chaos, Informative, ASMR, Thriller, Dance, Emotional), a brief 8-second script, a hyper-detailed first frame image prompt, and a separate, optimized Veo 3 image-to-video prompt. Output ONLY a clean, parsable, numbered text list.`;
            
            const { text: rawTextOutput } = await callText(
                [{ text: sysSearch + modePrompt }], 
                undefined, 
                undefined, 
                retryCount, 
                apiKey,
                [{ "google_search": {} }]
            );

            setStatus('Viral Architect: Structured data conversion in progress...');

            // STEP 2: Convert Raw Text to Structured JSON
            const sysConverter = `You are a strict data parser. Convert the following raw text list into a JSON array of objects following this schema: ${JSON.stringify(VIRAL_SCHEMA)}. Ensure you extract exactly 10 items.`;
            
            const { text: generatedJson } = await callText(
                [{ text: rawTextOutput }],
                sysConverter,
                VIRAL_SCHEMA,
                retryCount,
                apiKey
            );
            
            const parsedIdeas = JSON.parse(generatedJson);
            
            const ideasWithIds = parsedIdeas.map((idea, index) => ({
                id: index,
                ...idea,
                frameImage: null,
                frameStatus: 'pending'
            }));
            
            setViralIdeas(ideasWithIds);
            setShowViralModal(true);
            setStatus(`Viral Architect complete. ${ideasWithIds.length} concepts unleashed.`);
            AudioEngine.play('success');

        } catch (e) {
            setErr(`Viral Architect Error: ${String(e.message)}`);
            setStatus('Viral idea generation failed.');
            AudioEngine.play('error');
        } finally {
            setViralLoading(false);
        }
    }

    // --- Viral Idea Frame Generator (New Function) ---
    const generateViralIdeaFrame = useCallback(async (ideaId, prompt) => {
        AudioEngine.play('click');
        
        setViralIdeas(prev => prev.map(i => i.id === ideaId ? {...i, frameStatus: 'generating'} : i));
        
        try {
            const fullPrompt = `[VISUAL STYLE: ${visualStyle}, ASPECT RATIO: ${FIXED_ASPECT_RATIO}] ${prompt}`;
            
            const imageUrl = await callImage(fullPrompt, null, retryCount, apiKey);
            
            setViralIdeas(prev => prev.map(i => i.id === ideaId ? {...i, frameImage: imageUrl, frameStatus: 'success'} : i));
            AudioEngine.play('success');
            
        } catch (e) {
            setViralIdeas(prev => prev.map(i => i.id === ideaId ? {...i, frameStatus: 'error'} : i));
            console.error("Viral Frame Generation Failed:", e);
            AudioEngine.play('error');
        }
    }, [apiKey, visualStyle, FIXED_ASPECT_RATIO, retryCount]);


    const AnimatedWait = () => {
        const [tagline, setTagline] = useState('Conjuring Pixels...');
        const taglines = ['Directing Photons...', 'Weaving Narratives...', 'Synthesizing Vision...', 'Orchestrating Creativity...', 'Painting with Light...', 'Executing Quantum Tasks...', 'Loading Neural Network...'];

        const completedCount = scenes.filter(s => ['success', 'error'].includes(s.status)).length;
        const totalScenes = scenes.length;
        const progress = totalScenes > 0 ? Math.round((completedCount / totalScenes) * 100) : 0;

        useEffect(() => {
            if (!busy) return;
            const i = setInterval(() => setTagline(taglines[Math.floor(Math.random() * taglines.length)]), 1200);
            return () => clearInterval(i);
        }, [busy]);

        if (!busy) return null;

        return (
            <div className="fixed inset-0 z-[100] bg-black/95 backdrop-blur-md flex flex-col items-center justify-center font-sans">
                <div className="loader-orb" />
                <div className="mt-6 text-white text-4xl font-extrabold tracking-widest text-shadow-neon">{progress}%</div>
                <div className="w-80 h-3 bg-slate-900/70 rounded-full overflow-hidden mt-3 border border-cyan-500/50">
                    <div className="h-full bg-gradient-to-r from-cyan-400 to-blue-500 transition-all duration-300 ease-in-out" style={{ width: `${progress}%` }}></div>
                </div>
                <p className="mt-4 text-cyan-300 font-mono text-lg tracking-wider
                    animate-[floaty_2s_ease-in-out_infinite]">{tagline} <span className="text-sm text-slate-400">({completedCount}/{totalScenes} data packets)</span></p>
            </div>
        );
    };
    
    // Initial Animated Logo Splash Screen (Retained for dramatic effect)
    const isInitialLoading = useRef(true);
    useEffect(() => { isInitialLoading.current = false; }, []);

    if (isInitialLoading.current) {
        return (
            <div className="fixed inset-0 z-[100] bg-black flex items-center justify-center font-sans">
                <style jsx="true">{`
                    @keyframes spin { from {transform: rotate(0deg);} to {transform: rotate(360deg);} }
                    @keyframes floaty { 0% {transform: translateY(0)} 50% {transform: translateY(-4px)} 100%{transform: translateY(0)} }
                    .splash-logo { width: 120px; height: 120px; border-radius: 50%; filter: drop-shadow(0 0 24px rgba(0,255,255,1)); background: conic-gradient(from 0deg, #06b6d4 0 90deg, transparent 90deg 180deg, #60a5fa 180deg 270deg, transparent 270deg 360deg); animation: spin 1.2s cubic-bezier(0.68, -0.55, 0.27, 1.55) infinite; position: relative }
                    .splash-logo::after { content:""; position:absolute; inset: 15px; border-radius: 50%; background: radial-gradient(circle at 50% 50%, #000 70%, rgba(0,0,0,0)); }
                `}</style>
                <div className="flex flex-col items-center">
                    <div className="splash-logo mb-6"/>
                    <h1 className="text-4xl font-extrabold text-transparent bg-clip-text bg-gradient-to-r from-cyan-300 to-blue-500 tracking-widest text-shadow-neon animate-[floaty_1.5s_ease-in-out_infinite]">
                        DN AI FILM LAB
                    </h1>
                    <p className="text-sm text-cyan-500/80 font-mono tracking-widest mt-2 animate-pulse">QUANTUM STUDIO BOOTSTRAPPING V3000...</p>
                </div>
            </div>
        );
    }
    

    return (
        <div className="min-h-screen animated-bg text-gray-100 font-sans">
            {/* Dramatically Improved, Layered Animated Background */}
            <style jsx="true">{`
                @keyframes gradientFlow { 0% {background-position:0% 50%} 50% {background-position: 100% 50%} 100%{background-position: 0% 50%} }
                @keyframes floaty { 0% {transform: translateY(0)} 50% {transform: translateY(-4px)} 100%{transform: translateY(0)} }
                @keyframes pulseGrid { 0% {opacity: 0.05;} 50% {opacity: 0.25;} 100% {opacity: 0.05;} }
                @keyframes subtlePulse { 0% {opacity: 0.7;} 50% {opacity: 1.0;} 100% {opacity: 0.7;} }
                @keyframes spin { from {transform: rotate(0deg);} to {transform: rotate(360deg);} }
                @keyframes neonGlow { 0% {box-shadow: 0 0 5px #00ffff;} 50% {box-shadow: 0 0 20px #00ffff, 0 0 30px #06b6d4;} 100% {box-shadow: 0 0 5px #00ffff;} }
                @keyframes neonHover { 0% { box-shadow: 0 0 5px rgba(255,255,255,0.1); } 100% { box-shadow: 0 0 15px #00ffff, 0 0 25px #06b6d4; } }


                .animated-bg {
                    background-color: #000;
                    position: relative;
                    overflow: hidden;
                }
                /* Layer 1: Subtle Animated Grid */
                .animated-bg::before {
                    content: '';
                    position: absolute;
                    top: 0; left: 0; right: 0; bottom: 0;
                    background-image: linear-gradient(to right, #00ffff33 1px, transparent 1px),
                                      linear-gradient(to bottom, #00ffff33 1px, transparent 1px);
                    background-size: 40px 40px;
                    opacity: 0.1;
                    animation: pulseGrid 10s ease-in-out infinite;
                    pointer-events: none;
                }
                /* Layer 2: Deep Animated Noise/Starfield (using radial gradient to simulate depth) */
                .animated-bg::after {
                    content: '';
                    position: absolute;
                    top: 0; left: 0; right: 0; bottom: 0;
                    background: radial-gradient(circle at 100% 0%, #0369a120 0%, transparent 40%),
                                radial-gradient(circle at 0% 100%, #06b6d430 0%, transparent 40%),
                                linear-gradient(135deg, #000000 0%, #000000 50%, #0f172a 100%);
                    opacity: 1;
                    animation: gradientFlow 30s ease-in-out infinite alternate;
                    background-size: 300% 300%;
                    mix-blend-mode: hard-light;
                    pointer-events: none;
                    z-index: -1;
                }
                
                /* 2220 Digital Glass Pane (Increased depth and contrast) */
                .glass-pane {
                    background: rgba(0, 8, 20, 0.75); /* Darker base for better readability */
                    backdrop-filter: blur(18px) brightness(1.2);
                    border: 1px solid rgba(0,255,255,.4);
                    box-shadow: 0 0 25px rgba(0,255,255,.15), inset 0 0 8px rgba(0,255,255,.05); /* Enhanced cyan glow/inset */
                    transition: box-shadow 0.3s ease, border-color 0.3s ease;
                }
                .glass-pane:hover {
                    border-color: rgba(0,255,255,.6);
                }

                /* Neon Button Hover Effect */
                .premium-button { 
                    transition: all .3s cubic-bezier(0.4, 0, 0.2, 1); 
                    transform-style: preserve-3d;
                    position: relative;
                }
                .premium-button:hover:not(:disabled) {
                    transform: translateY(-3px);
                    box-shadow: 0 5px 20px rgba(0,255,255,.6);
                    border-color: #00ffff;
                }

                /* Active/Focus Animation for Inputs */
                .input-active-glow:focus {
                    box-shadow: 0 0 8px #00ffff;
                    border-color: #00ffff;
                    outline: none;
                }
                /* Neon Text Shadow */
                .text-shadow-neon {
                    text-shadow: 0 0 6px #00ffff, 0 0 12px #00ffff;
                }
                /* Loader Orb (Fast Pulse) */
                .loader-orb { width: 120px; height: 120px; border-radius: 50%; filter: drop-shadow(0 0 24px rgba(0,255,255,1)); background: conic-gradient(from 0deg, #06b6d4 0 90deg, transparent 90deg 180deg, #60a5fa 180deg 270deg, transparent 270deg 360deg); animation: spin 0.8s linear infinite; position: relative }
                .loader-orb::after { content:""; position:absolute; inset: 15px; border-radius: 50%; background: radial-gradient(circle at 50% 50%, #000 70%, rgba(0,0,0,0)); }
            `}</style>

            <AnimatedWait />

            <header className="sticky top-0 z-40 border-b-2 border-cyan-400/40 backdrop-blur-3xl bg-black/80">
                <div className="max-w-screen-2xl mx-auto px-4 sm:px-6 lg:px-8 py-4 flex items-center gap-4">
                    <ZapIcon size={36} className="text-cyan-400 animate-pulse text-shadow-neon" />
                    <div className="flex-1">
                        <h1 className="text-3xl font-extrabold text-transparent bg-clip-text bg-gradient-to-r from-cyan-300 to-blue-500 tracking-widest text-shadow-neon">
                            DN AI <span className="text-lg text-slate-300 font-medium">| FILM LAB: QUANTUM STUDIO</span>
                        </h1>
                        <p className="text-xs text-cyan-500/80 font-mono tracking-widest">V3000 QUANTUM EDITION ONLINE</p>
                    </div>
                    <div className="flex items-center gap-4">
                         <button onClick={handleSaveState} disabled={busy || scenes.length === 0}
                            className="premium-button flex items-center gap-2 text-xs px-3 py-2 rounded-lg bg-green-900/40 hover:bg-green-800/60 border border-green-500/30 font-bold disabled:opacity-50">
                            <Save size={14} /> SAVE STATE
                        </button>
                        <div className="flex items-center gap-2 text-green-400 font-extrabold bg-green-900/30 px-3 py-1.5 rounded-full text-sm border border-green-500/50">
                            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="lucide lucide-dollar-sign"><line x1="12" x2="12" y1="2" y2="22"/><path d="M17 5H9.5a3.5 3.5 0 0 0 0 7h5a3.5 3.5 0 0 1 0 7H6"/></svg>
                            {creditsUsed.toFixed(2)} CREDITS
                        </div>

                        <button onClick={() => { AudioEngine.play('click'); setShowHistoryModal(true); }}
                            className="premium-button flex items-center gap-2 text-xs px-3 py-2 rounded-lg bg-slate-900/80 hover:bg-cyan-900/60 border border-cyan-500/30 font-bold">
                            <Clock size={14} /> HISTORY LOG
                        </button>

                        <button onClick={() => { AudioEngine.play('click'); setShowSettings(true); }}
                            className="premium-button flex items-center gap-2 text-xs px-3 py-2 rounded-lg bg-slate-900/80 hover:bg-cyan-900/60 border border-cyan-500/30 font-bold">
                            <Settings size={14} /> CONSOLE
                        </button>
                    </div>
                </div>
            </header>

            <main className="max-w-screen-2xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6 px-4 sm:px-6 lg:px-8 py-6">

                {/* Left Sidebar: Configuration and Input */}
                <section className="lg:col-span-3 space-y-4">

                    {/* Autopilot Mode & Branding Toggle */}
                    <div className="glass-pane rounded-xl p-4 border-cyan-400/40 animate-[neonGlow_2s_ease-in-out_infinite_alternate_0.5s]">
                        <h2 className="font-extrabold mb-3 text-cyan-300 flex items-center gap-2"><Layers size={16} className='text-yellow-400'/> OPERATIONAL LAYERS</h2>
                        <div className="space-y-3">
                             {/* Autopilot */}
                            <div className="flex items-center justify-between transition duration-200 hover:bg-slate-900/50 p-1 rounded-md">
                                <label htmlFor="autoExecuteToggle" className="text-sm font-mono text-cyan-300">AUTO-EXECUTE SYNTHESIS</label>
                                <input type="checkbox" id="autoExecuteToggle" checked={autoExecute} onChange={() => setAutoExecute(!autoExecute)}
                                    className="h-4 w-4 rounded bg-slate-700 text-cyan-500 border-none focus:ring-0 cursor-pointer" />
                            </div>
                            {/* Branding Mode */}
                            <div className="flex items-center justify-between border-t border-slate-700/50 pt-3 transition duration-200 hover:bg-slate-900/50 p-1 rounded-md">
                                <label htmlFor="brandingModeToggle" className="text-sm font-mono text-red-400 flex items-center">
                                    BRANDING MODE (SPONSOR INTEGRATION) {brandingOutput && <CheckCircle size={14} className='ml-2 text-green-400' />}
                                </label>
                                <input type="checkbox" id="brandingModeToggle" checked={isBrandingMode} onChange={() => {
                                    setIsBrandingMode(!isBrandingMode);
                                    if(isBrandingMode) { setBrandingOutput(null); setLogoDescription(null); }
                                }}
                                    className="h-4 w-4 rounded bg-slate-700 text-red-500 border-none focus:ring-0 cursor-pointer" />
                            </div>
                        </div>
                    </div>


                    <div className="glass-pane rounded-xl p-4 border-cyan-400/40">
                        <h2 className="font-extrabold mb-3 text-cyan-300 flex items-center gap-2"><ImageIcon size={16} /> VISUAL MATRIX CONFIG</h2>
                        <div className="grid grid-cols-2 gap-3">
                            <select value={visualStyle} onChange={e => setVisualStyle(e.target.value)}
                                className="w-full bg-slate-900/70 border border-cyan-700 rounded-md px-2 py-2 text-sm focus:ring-cyan-500 focus:border-cyan-500 font-mono input-active-glow">
                                <option>Cinematic Photorealistic</option><option>Noir Comic Book</option><option>Modern Anime</option>
                                <option>Vintage Cartoon</option><option>Hollywood Glamour</option><option>3D Render</option>
                                <option>Cyberpunk Neon</option><option>Fantasy Art</option>
                            </select>
                            
                            {/* NEW: ASPECT RATIO LOCK INDICATOR */}
                            <div className="w-full bg-slate-800 border border-green-700 rounded-md px-2 py-2 text-sm font-mono flex items-center justify-between shadow-lg animate-pulse">
                                <span className="text-green-300">16:9 Widescreen Lock</span>
                                <Lock size={16} className="text-green-400" />
                            </div>
                        </div>
                        
                        {/* Continuity Lock */}
                        <div className="mt-4 border-t border-slate-700/50 pt-4">
                            <label className="block text-xs text-gray-400 mb-1 font-mono">Reference Character Image (Continuity Lock)</label>
                            <input type="file" accept="image/*" onChange={async e => {
                                if (e.target.files?.[0]) setRefImg(await fileToBase64(e.target.files[0]));
                            }}
                                className="w-full text-xs file:mr-2 file:py-1 file:px-2 file:rounded-full file:border-0 file:text-xs
                                       file:bg-cyan-700/50 hover:file:bg-cyan-600/70 file:text-white cursor-pointer"/>
                            <div className="mt-2 flex items-center gap-2 text-sm">
                                <input id="charLock" type="checkbox" checked={charLock} onChange={e => setCharLock(e.target.checked)}
                                    className="h-4 w-4 rounded bg-slate-700 text-cyan-500 border-none focus:ring-0 cursor-pointer" />
                                <label htmlFor="charLock" className="text-sm font-mono text-cyan-300">ENABLE CHARACTER LOCK</label>
                            </div>
                        </div>

                        {/* Logo Reference Input (Brand Lock) */}
                        <div className="mt-4 border-t border-slate-700/50 pt-4">
                            <label className="block text-xs text-gray-400 mb-1 font-mono">Reference LOGO Image (Brand Lock)</label>
                            <input type="file" accept="image/*" onChange={async e => {
                                if (e.target.files?.[0]) setLogoRefImg(await fileToBase64(e.target.files[0]));
                            }}
                                className="w-full text-xs file:mr-2 file:py-1 file:px-2 file:rounded-full file:border-0 file:text-xs
                                        file:bg-red-700/50 hover:file:bg-red-600/70 file:text-white cursor-pointer"/>
                            {logoRefImg && (
                                <div className='flex justify-between items-center mt-1'>
                                    <p className="text-xs text-red-500 truncate font-mono">
                                        LOGO STATUS: {logoDescription ? `ANALYSIS COMPLETE (${logoDescription.shape})` : 'READY FOR ANALYSIS'}
                                    </p>
                                    <button onClick={() => { AudioEngine.play('click'); setLogoRefImg(null); setLogoDescription(null); }} className='text-xs text-red-500 hover:text-red-300 font-mono'>[CLEAR LOGO]</button>
                                </div>
                            )}
                        </div>
                    </div>

                    <div className="glass-pane rounded-xl p-4 border-cyan-400/40">
                        <h2 className="font-extrabold mb-2 text-cyan-300 flex items-center gap-2"><FileText size={16} /> DATA STREAM INGEST</h2>

                        <label className="block text-xs text-gray-400 mb-1 font-mono">Upload PDF/DOCX/TXT (AI DEEP-SCAN $0.05)</label>
                        <input type="file" accept=".pdf, .docx, .txt, application/pdf, application/vnd.openxmlformats-officedocument.wordprocessingml.document, text/plain" onChange={handleScriptUpload}
                            className="w-full text-xs file:mr-2 file:py-1 file:px-2 file:rounded-full file:border-0 file:text-xs
                               file:bg-blue-600 hover:file:bg-blue-500 file:text-white cursor-pointer"/>
                        {scriptFile && <p className="text-xs text-slate-500 mt-1 truncate font-mono">SOURCE: {scriptFile}</p>}


                        <label className="block text-xs text-gray-400 mt-3 mb-1 font-mono">NARRATIVE INPUT (Auto-Enhanced)</label>
                        <textarea value={narrative}
                            onChange={e => setNarrative(e.target.value)} rows={8}
                            className="w-full bg-slate-900/70 border border-cyan-700 rounded-md p-2 text-sm font-mono text-cyan-300 focus:ring-cyan-500 focus:border-cyan-500 input-active-glow
                                     animate-[subtlePulse_4s_ease-in-out_infinite]"></textarea>

                        {/* TTS Voice Selector */}
                        <div className='mt-3'>
                            <label className="block text-xs text-gray-400 mb-1 font-mono">VOICE MATRIX SELECTION</label>
                            <select
                                value={selectedVoice}
                                onChange={(e) => setSelectedVoice(e.target.value)}
                                className="w-full bg-slate-900/70 border border-purple-700 rounded-md px-2 py-2 text-sm focus:ring-purple-500 focus:border-purple-500 font-mono text-purple-300 input-active-glow"
                            >
                                {TTS_VOICES.map(v => (
                                    <option key={v.voiceName} value={v.voiceName}>
                                        {v.name}
                                    </option>
                                ))}
                            </select>
                        </div>

                        {/* TTS Feature Button (AI Voiceover Creator) */}
                        <div className="mt-3">
                            <button onClick={handleTtsCreation} disabled={!narrative || ttsLoading}
                                className="premium-button w-full px-2 py-2 text-sm font-semibold rounded-md bg-purple-900/50 border border-purple-500/30 hover:bg-purple-800/60 disabled:opacity-40 disabled:cursor-not-allowed flex items-center justify-center gap-2">
                                {ttsLoading ? <Loader2 size={16} className="animate-spin text-purple-400" /> : <Volume2 size={14} className="text-purple-400" />}
                                ✨ AI VOICEOVER CREATOR
                            </button>
                            {ttsAudioUrl && (
                                <button onClick={handleDownloadAudio}
                                    className="premium-button w-full mt-2 px-2 py-2 text-sm font-semibold rounded-md bg-cyan-600 hover:bg-cyan-500 flex items-center justify-center gap-2">
                                    <Download size={14} /> DOWNLOAD AUDIO (.WAV)
                                </button>
                            )}
                            <audio ref={audioRef} controls className="mt-2 w-full h-8 hidden" onPlay={() => AudioEngine.play('click')}></audio>
                        </div>
                    </div>

                    <div className="glass-pane rounded-xl p-4 border-cyan-400/40">
                        <h2 className="font-extrabold mb-3 text-cyan-300 flex items-center gap-2"><BrainCircuit size={16} /> CORE DIRECTOR MODULES</h2>
                        <button onClick={runAiDirector} disabled={!narrative || busy}
                            className="premium-button w-full px-2 py-2 text-sm font-bold rounded-lg bg-gradient-to-r from-blue-600 to-cyan-600 text-white shadow-lg hover:from-blue-500 hover:to-cyan-500 disabled:bg-slate-700/50 disabled:cursor-not-allowed
                                         animate-[subtlePulse_4s_ease-in-out_infinite_1s]">
                            <span className="flex items-center gap-2"><BrainCircuit size={16} /> INITIATE VISION MATRIX</span>
                        </button>

                        {/* Branding Architect Button */}
                        <button onClick={runBrandingArchitect} disabled={!isBrandingMode || !predicted?.length || busy}
                             className="premium-button w-full px-2 py-2 text-sm font-semibold rounded-lg bg-red-900/50 border border-red-500/30 hover:bg-red-800/60 disabled:opacity-40 disabled:cursor-not-allowed flex items-center justify-center gap-2 mt-3">
                             <Users size={14} className="text-red-400" /> ✨ BRANDING ARCHITECT
                        </button>
                        
                        {/* Matrix Tools Container */}
                        <div className='mt-4 border-t border-slate-700 pt-3'>
                            <h3 className="font-extrabold mb-2 text-sm text-yellow-400 flex items-center gap-2"><List size={16}/> MATRIX TOOLS (CYBER-ANALYTICS)</h3>
                            <div className='grid grid-cols-2 gap-2'>
                                <button onClick={runComplexityCipher} disabled={!directorsVision || busy}
                                    className="premium-button px-2 py-2 text-xs font-semibold rounded-lg bg-indigo-900/50 border border-indigo-500/30 hover:bg-indigo-800/60 disabled:opacity-40 disabled:cursor-not-allowed flex items-center justify-center gap-1">
                                    <Cpu size={12} /> COMPLEXITY CIPHER
                                </button>
                                <button onClick={runFlowAuditor} disabled={!directorsVision || busy}
                                    className="premium-button px-2 py-2 text-xs font-semibold rounded-lg bg-purple-900/50 border border-purple-500/30 hover:bg-purple-800/60 disabled:opacity-40 disabled:cursor-not-allowed flex items-center justify-center gap-1">
                                    <TrendingUp size={12} /> NARRATIVE FLOW
                                </button>
                                <button onClick={runScriptPurityFilter} disabled={!directorsVision || busy}
                                    className="premium-button px-2 py-2 text-xs font-semibold rounded-lg bg-teal-900/50 border border-teal-500/30 hover:bg-teal-800/60 disabled:opacity-40 disabled:cursor-not-allowed flex items-center justify-center gap-1">
                                    <BookOpen size={12} /> SCRIPT PURITY FILTER
                                </button>
                            </div>

                            {/* Asset Descriptor (requires input) */}
                            <div className='mt-3'>
                                <input type='text' value={assetDescPrompt} onChange={e => setAssetDescPrompt(e.target.value)} placeholder="Describe asset for fabrication..."
                                    className="w-full bg-slate-900/70 border border-yellow-700 rounded-md p-2 text-xs font-mono text-yellow-300 focus:ring-yellow-500 focus:border-yellow-500 input-active-glow"/>
                                <button onClick={runAssetDescriptor} disabled={!assetDescPrompt || busy}
                                    className="premium-button w-full px-2 py-2 text-xs font-semibold rounded-lg bg-yellow-900/50 border border-yellow-500/30 hover:bg-yellow-800/60 disabled:opacity-40 disabled:cursor-not-allowed flex items-center justify-center gap-1 mt-2">
                                    <Map size={12} /> VISUAL ASSET DESCRIPTOR
                                </button>
                            </div>
                        </div>
                        
                        {/* Viral Video Architect Mode Selector & Button */}
                        <div className='mt-4 border-t border-slate-700 pt-3'>
                            <h3 className="font-extrabold mb-2 text-sm text-green-400 flex items-center gap-2"><ZapIcon size={16}/> VIRAL VIDEO ARCHITECT</h3>
                            
                            <div className='space-y-2'>
                                <input type='text' value={viralBrandName} onChange={e => setViralBrandName(e.target.value)} placeholder="Optional: Brand Name (e.g., Quantum Beverages)"
                                    className="w-full bg-slate-900/70 border border-green-700 rounded-md p-2 text-xs font-mono text-white focus:ring-green-500 focus:border-green-500 input-active-glow"/>
                                <input type='text' value={viralProduct} onChange={e => setViralProduct(e.target.value)} placeholder="Optional: Product (e.g., Luminous Shoe Laces)"
                                    className="w-full bg-slate-900/70 border border-green-700 rounded-md p-2 text-xs font-mono text-white focus:ring-green-500 focus:border-green-500 input-active-glow"/>
                            </div>
                            
                            <select
                                value={viralMode}
                                onChange={e => setViralMode(e.target.value)}
                                className="w-full bg-slate-900/70 border border-green-700 rounded-md px-2 py-2 text-xs font-mono text-green-300 focus:ring-green-500 focus:border-green-500 input-active-glow mt-2"
                            >
                                <option value="general">GENERAL CONCEPTS (Viral)</option>
                                <option value="ads">HIGH-END AD CONCEPTS</option>
                            </select>
                            
                            <button onClick={runViralVideoArchitect} disabled={busy || viralLoading || (viralMode === 'ads' && !viralBrandName && !viralProduct)}
                                className="premium-button w-full px-2 py-2 text-sm font-bold rounded-lg bg-green-600 hover:bg-green-500 text-black shadow-lg disabled:opacity-40 disabled:cursor-not-allowed flex items-center justify-center gap-2 mt-2 animate-[neonGlow_1.5s_ease-in-out_infinite_alternate]">
                                {viralLoading ? <Loader2 size={16} className="animate-spin text-black" /> : '⚡️ UNLEASH CHAOS ⚡️'}
                            </button>
                        </div>

                    </div>

                    {err && (
                        <div className="bg-red-900/40 border-2 border-red-500/80 p-3 rounded-xl text-red-300 text-sm font-mono">
                            <p className="font-extrabold">CRITICAL ERROR (CODE RED):</p>
                            <p className="mt-1">{err}</p>
                        </div>
                    )}
                </section>

                {/* Right Content: Status, Prompts, and Scenes */}
                <section className="lg:col-span-9 space-y-4">
                    <div className="glass-pane rounded-xl p-3 text-center text-sm font-mono tracking-wider border-cyan-400/60 bg-black/70 animate-[neonGlow_3s_ease-in-out_infinite_alternate]">
                        SYSTEM LOG: <span className={cn(busy || ttsLoading ? 'text-yellow-400 text-shadow-neon animate-pulse' : 'text-cyan-400 text-shadow-neon', 'font-extrabold')}>{status}</span>
                    </div>

                    {scenes.length > 0 ? (
                        // Displaying Generated Scenes
                        <div className="grid grid-cols-1 md:grid-cols-2 xl:grid-cols-3 gap-4">
                            {scenes.map(s => (
                                <div key={s.timestamp || s.id} className="glass-pane rounded-xl overflow-hidden flex flex-col shadow-2xl border-cyan-400/30 hover:border-cyan-200/50 transition-all duration-300">
                                    <div className="px-3 py-2 border-b border-cyan-500/40 flex items-center justify-between bg-slate-900/70">
                                        <div className="text-sm font-bold truncate pr-2 text-cyan-200">{s.sceneHeader}</div>
                                        <span className={cn('text-xs px-2 py-0.5 rounded-full font-bold font-mono',
                                            s.status === 'success' && 'bg-green-600/30 text-green-300 border border-green-500',
                                            s.status === 'error' && 'bg-red-600/30 text-red-300 border border-red-500',
                                            s.status === 'queued' && 'bg-slate-700/30 text-slate-300 border border-slate-500',
                                            (s.status === 'generating' || s.status === 'starting' || String(s.status).startsWith('retrying') || s.status === 'optimizing') && 'bg-blue-600/30 text-blue-300 animate-pulse border border-blue-500'
                                        )}
                                        >{String(s.status).includes('retrying') ? 'RETRY' : s.status.toUpperCase()}</span>
                                    </div>
                                    <div className={cn('relative bg-black/90 transition-all duration-300', aspectRatioClass)}>
                                        {['generating', 'starting', 'optimizing'].includes(s.status) || String(s.status).startsWith('retrying') ? (
                                            <div className="absolute inset-0 flex items-center justify-center">
                                                <div className="loader-orb w-16 h-16" />
                                            </div>
                                        ) : s.image ? (
                                            <img src={s.image} alt={s.sceneHeader} className="w-full h-full object-cover transition-opacity duration-500" />
                                        ) : (
                                            <div className="absolute inset-0 flex items-center justify-center text-slate-500 text-xs p-2 text-center bg-slate-900/80 font-mono">{s.status === 'error' ? (s.error || 'ERROR: FRAME DATA CORRUPTED') : 'QUEUED... AWAITING EXECUTION.'}</div>
                                        )}
                                    </div>
                                    <div className="p-3 border-t border-cyan-500/20">
                                        <textarea value={s.prompt} readOnly
                                            className="w-full bg-slate-900/50 border-0 rounded-md p-2 text-xs h-24 cursor-default resize-none text-cyan-400 font-mono"></textarea>
                                    </div>
                                    <div className="px-3 py-2 border-t border-cyan-500/20 flex items-center justify-end gap-2 bg-slate-900/70">
                                        {s.image && <button onClick={() => { AudioEngine.play('click'); setEditingScene(s); setEditRefImg(null); }}
                                            className="premium-button p-2 rounded-lg bg-slate-700/50 hover:bg-yellow-900/50 border border-yellow-400/40" title="Edit Frame"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="lucide lucide-wand-2 text-yellow-400"><path d="m21.7 4.3-1.9 1.9"/><path d="m18.2 8.8-1.9 1.9"/><path d="M16.7 13.3 15 15l-1.9-1.9"/><path d="M9.6 15.6.8 2.8C.2 2.2-.2 1.4 0 .9c.2-.5.8-.8 1.4-1.1L14.2 14.4c.5.5.9 1 1 1.6s-.3 1.2-.8 1.4c-.5.2-1.3-.2-1.8-.8l-12.8-12.8Z"/><path d="M7 7.5 1 1.5"/><path d="m14 14.5 6 6"/></svg></button>}
                                        <button onClick={() => regenerateScene(s.id)} disabled={busy}
                                            className="premium-button p-2 rounded-lg bg-slate-700/50 hover:bg-orange-900/50 border border-orange-400/40 disabled:opacity-50" title="Retry"><RotateCw size={14} className='text-orange-400'/></button>
                                        {s.image && <button onClick={() => {
                                            AudioEngine.play('click');
                                            const a = document.createElement('a');
                                            a.href = s.image;
                                            a.download = `DN_AI_Frame_${s.id}.png`;
                                            a.click();
                                        }} className="premium-button p-2 rounded-lg bg-cyan-600 hover:bg-cyan-500 border border-cyan-400" title="Download"><Download size={14} /></button>}
                                    </div>
                                </div>
                            ))}
                        </div>
                    ) : predicted ? (
                        // Displaying Predicted Prompts
                        <div className="glass-pane rounded-xl p-6 border-cyan-400/40 animate-[neonGlow_2s_ease-in-out_infinite_alternate]">
                            <h2 className="font-extrabold text-xl text-cyan-300 border-b-2 border-cyan-500/50 pb-2 mb-4">SEGMENTATION PROTOCOL READY</h2>
                            <p className="text-sm text-slate-400 mb-4 font-mono">DIRECTOR MODULE CONFIRMED {predicted.length} VISUAL SEGMENTS. INITIATE QUANTUM SYNTHESIS BELOW.</p>
                            <ol className="divide-y divide-slate-800 space-y-3">
                                {predicted.map(s => (
                                    <li key={s.id} className="py-3">
                                        <div className="text-sm font-bold text-cyan-300 flex items-center gap-2">
                                            <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="lucide lucide-film text-blue-400"><rect width="20" height="20" x="2" y="2" rx="2.18" ry="2.18"/><line x1="7" x2="7" y1="2" y2="22"/><line x1="17" x2="17" y1="2" y2="22"/><line x1="2" x2="22" y1="12" y2="12"/></svg>
                                            {s.sceneHeader}
                                        </div>
                                        <textarea value={s.prompt} readOnly
                                            className="mt-1 w-full bg-slate-900/70 border border-cyan-700 rounded-md p-2 text-xs h-24 cursor-default resize-none text-cyan-400 font-mono"></textarea>
                                    </li>
                                ))}
                            </ol>
                            <div className="mt-6">
                                <button onClick={generateAllImages} disabled={busy}
                                    className="premium-button w-full px-3 py-3 text-lg font-bold rounded-lg bg-gradient-to-r from-green-500 to-teal-600 text-black shadow-xl hover:from-green-400 hover:to-teal-500 disabled:bg-slate-700/50 disabled:opacity-50 border border-white">
                                    EXECUTE FRAME SYNTHESIS (${(predicted.length * 0.10).toFixed(2)})
                                </button>
                            </div>
                        </div>
                    ) : (
                        // Welcome State
                        <div className="glass-pane rounded-xl p-8 text-center flex flex-col items-center justify-center min-h-[50vh]">
                            <Sparkles size={72} className="text-cyan-400 text-shadow-neon animate-pulse" />
                            <div className="text-5xl font-extrabold text-transparent bg-clip-text bg-gradient-to-r from-cyan-300 to-blue-500 mt-4 tracking-widest text-shadow-neon">QUANTUM STUDIO ONLINE</div>
                            <p className="text-gray-400 mt-2 max-w-md font-mono">DN AI FILM LAB: THE NEXT GENERATION OF CINEMATIC PIPELINES. LOAD SCRIPT AND INITIATE CORE MODULES TO BEGIN.</p>
                            <button onClick={() => document.querySelector('textarea')?.focus()}
                                className="premium-button mt-6 px-8 py-3 text-base font-extrabold bg-gradient-to-r from-cyan-500 to-blue-600 hover:from-cyan-400 hover:to-blue-500 rounded-lg shadow-xl border-white">START NEW PROJECT</button>
                        </div>
                    )}
                </section>
            </main>

            {/* Modals */}
            
            {/* 1. Director's Vision Modal */}
            {showVisionModal && directorsVision && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => setShowVisionModal(false)}>
                    <div className="glass-pane rounded-xl shadow-2xl w-full max-w-3xl max-h-[90vh] flex flex-col border-yellow-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 border-b-2 border-cyan-500/50"><h2 className="font-extrabold text-2xl text-yellow-400 flex items-center gap-2"><BrainCircuit size={24} /> DIRECTOR'S VISION MATRIX V.3.1</h2></div>
                        <div className="p-4 overflow-y-auto space-y-4 text-sm">
                            <VisionDetail title="CORE THEME">{directorsVision.core_theme}</VisionDetail>
                            <VisionDetail title="VISUAL TONE">{directorsVision.visual_tone}</VisionDetail>
                            <VisionDetail title="CINEMATOGRAPHY">{directorsVision.cinematography_style}</VisionDetail>
                            <VisionDetail title="MAIN NARRATIVE GOAL">{directorsVision.main_goal}</VisionDetail>
                            {characterSheet && <VisionDetail title={`CHARACTER SHEET (${directorsVision.main_character})`}>{characterSheet}</VisionDetail>}
                            <VisionDetail title="CINEMATICALLY ENHANCED SCRIPT (Snippet)">{String(directorsVision.enhanced_script).slice(0, 300)}...</VisionDetail>
                        </div>
                        <div className="p-4 mt-auto border-t-2 border-cyan-500/50 flex justify-end gap-3 bg-slate-900/50">
                            <button onClick={() => { AudioEngine.play('click'); setShowVisionModal(false); }} className="premium-button px-4 py-2 text-sm bg-slate-700 hover:bg-slate-600 rounded-lg font-bold">DISMISS</button>
                            <button onClick={generateScenesFromVision} disabled={busy}
                                className="premium-button px-4 py-2 text-sm bg-cyan-600 hover:bg-cyan-500 rounded-lg disabled:opacity-50 font-bold border border-white">
                                {autoExecute ? 'ACCEPT & AUTO-EXECUTE' : 'PROCEED TO SEGMENTATION'}
                            </button>
                        </div>
                    </div>
                </div>
            )}
            
            {/* 2. Image Edit Modal */}
            {editingScene && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => { setEditingScene(null); setEditRefImg(null); }}>
                    <div className="glass-pane rounded-xl w-full max-w-lg border-yellow-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 border-b-2 border-cyan-500/50"><h2 className="font-extrabold text-xl text-yellow-400">FRAME EDIT PROTOCOL</h2></div>
                        <div className="p-4 space-y-4">
                            <img src={editRefImg || editingScene.image} alt="Editing preview"
                                className="rounded-lg w-full object-contain max-h-64 border border-slate-700" />

                            <VisionDetail title="UPLOAD REFERENCE IMAGE (Optional)">
                                <input type="file" accept="image/*" onChange={async e => {
                                    if (e.target.files?.[0]) setEditRefImg(await fileToBase64(e.target.files[0]));
                                }}
                                    className="w-full text-xs file:mr-2 file:py-1 file:px-2 file:rounded-full file:border-0 file:text-xs
                                        file:bg-yellow-700/50 hover:file:bg-yellow-600/70 file:text-white cursor-pointer"/>
                                {editRefImg && <p className="text-xs text-yellow-500 mt-1 font-mono">Reference image loaded. This will override the generated image as the base for the edit.</p>}
                            </VisionDetail>

                            <VisionDetail title="EDIT PROMPT">
                                <textarea value={editPrompt} onChange={e => setEditPrompt(e.target.value)} placeholder="ENTER PRECISE VISUAL INSTRUCTIONS" rows={3}
                                    className="w-full bg-slate-900 border-yellow-700 rounded-md p-2 text-sm font-mono text-yellow-300 focus:ring-yellow-500 focus:border-yellow-500 input-active-glow"></textarea>
                            </VisionDetail>

                        </div>
                        <div className="p-4 flex justify-end gap-3 bg-slate-900/50 border-t-2 border-cyan-500/50">
                            <button onClick={() => { AudioEngine.play('click'); setEditingScene(null); setEditRefImg(null); setEditPrompt(''); }}
                                className="premium-button px-4 py-2 text-sm bg-slate-700 rounded-lg hover:bg-slate-600 font-bold">CANCEL</button>
                            <button onClick={handleEditImage} disabled={isEditing || !editPrompt}
                                className="premium-button px-4 py-2 text-sm bg-yellow-600 rounded-lg hover:bg-yellow-500 disabled:opacity-50 text-black font-extrabold border border-black">
                                {isEditing ? <Loader2 size={16} className="animate-spin text-black" /> : 'APPLY EDIT ($0.10)'}
                            </button>
                        </div>
                    </div>
                </div>
            )}
            
            {/* 3. Branding Report Modal */}
            {showBrandingModal && brandingOutput && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => setShowBrandingModal(false)}>
                    <div className="glass-pane rounded-xl w-full max-w-4xl max-h-[90vh] flex flex-col border-red-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 flex justify-between items-center border-b-2 border-cyan-500/50">
                            <h2 className="font-extrabold text-xl text-red-400 flex items-center gap-2"><Users size={20}/> BRAND INTEGRATION ARCHITECT REPORT</h2>
                            <button onClick={() => { AudioEngine.play('click'); setShowBrandingModal(false); }} className="p-1 rounded-full hover:bg-slate-700"><X size={20} /></button>
                        </div>
                        <div className="p-4 overflow-y-auto space-y-6">
                            <p className='text-xs text-slate-400 font-mono border-b border-slate-700 pb-2'>INTEGRATION PLAN READY. PROMPTS WILL BE INJECTED INTO SYNTHESIS.</p>
                            {logoDescription && (
                                <div className='p-3 bg-slate-800/70 rounded-lg border border-red-700'>
                                    <h3 className='font-extrabold text-sm text-cyan-300'>LOGO ANALYSIS (BRAND LOCK DATA)</h3>
                                    <p className='text-xs font-mono text-slate-400 mt-1'>
                                        <span className='font-extrabold text-red-300'>COLOR:</span> {logoDescription.color} | <span className='font-extrabold text-red-300'>SHAPE:</span> {logoDescription.shape} | <span className='font-extrabold text-red-300'>MATERIALS:</span> {logoDescription.materials}
                                    </p>
                                </div>
                            )}
                             {brandingOutput.map((item, index) => (
                                 <div key={index} className="space-y-3 p-4 bg-slate-900/50 rounded-lg border border-red-700">
                                     <h3 className="font-bold text-lg text-red-300">{item.sceneHeader}</h3>
                                     <div className='text-xs font-mono space-y-2'>
                                         <p><span className='font-extrabold text-cyan-300'>PROMPT ADDITION:</span> <span className='text-white'>{item.scene_prompt_addition}</span></p>

                                         <div className='p-2 bg-slate-800/70 rounded'>
                                            <p className='font-extrabold text-yellow-400 mb-1'>ASSET INTEGRATION PLAN:</p>
                                            <ul className='list-disc list-inside space-y-1 pl-4'>
                                                {item.brand_assets.map((asset, i) => (
                                                    <li key={i} className='text-slate-400'>
                                                        <span className='font-extrabold uppercase text-white'>{asset.asset_name}:</span> <span className='text-slate-500'>Material: {asset.material_finish} / Placement: {asset.placement} / Notes: {asset.continuity_notes}</span>
                                                    </li>
                                                ))}
                                            </ul>
                                         </div>

                                         <p><span className='font-extrabold text-green-400'>SAFETY CHECK (PASS):</span> <span className='text-green-300'>{item.safety_checks}</span></p>
                                     </div>
                                 </div>
                             ))}
                        </div>
                        <div className="p-4 mt-auto border-t-2 border-cyan-500/50 bg-slate-900/50">
                            <button onClick={() => {AudioEngine.play('click'); setShowBrandingModal(false);}}
                                className="premium-button w-full px-4 py-2 text-sm bg-slate-700 hover:bg-slate-600 rounded-lg font-bold">CLOSE REPORT</button>
                        </div>
                    </div>
                </div>
            )}
            
            {/* 4. Scene Complexity Cipher Modal */}
            {showComplexityModal && complexityReport && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => setShowComplexityModal(false)}>
                    <div className="glass-pane rounded-xl w-full max-w-4xl max-h-[90vh] flex flex-col border-indigo-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 flex justify-between items-center border-b-2 border-cyan-500/50">
                            <h2 className="font-extrabold text-xl text-indigo-400 flex items-center gap-2"><Cpu size={20}/> SCENE COMPLEXITY CIPHER (1-10)</h2>
                            <button onClick={() => { AudioEngine.play('click'); setShowComplexityModal(false); }} className="p-1 rounded-full hover:bg-slate-700"><X size={20} /></button>
                        </div>
                        <div className="p-4 overflow-y-auto space-y-6">
                            <p className='text-xs text-slate-400 font-mono border-b border-slate-700 pb-2'>PRODUCTION EFFORT QUANTIFICATION (10 = MAX EFFORT/COST)</p>
                             {complexityReport.map((item, index) => (
                                 <div key={index} className="space-y-3 p-4 bg-slate-900/50 rounded-lg border border-indigo-700">
                                     <h3 className="font-bold text-lg text-cyan-300">{item.scene}</h3>
                                     <div className='grid grid-cols-3 gap-4 text-xs font-mono text-white'>
                                        <div><span className='font-extrabold text-red-400'>VFX:</span> {item.vfx_complexity}/10</div>
                                        <div><span className='font-extrabold text-yellow-400'>LOCATION:</span> {item.location_difficulty}/10</div>
                                        <div><span className='font-extrabold text-green-400'>ACTION:</span> {item.action_density}/10</div>
                                     </div>
                                     <p className='text-xs font-mono text-slate-400'><span className='font-extrabold text-indigo-300'>SUMMARY:</span> {item.summary}</p>
                                 </div>
                             ))}
                        </div>
                        <div className="p-4 mt-auto border-t-2 border-cyan-500/50 bg-slate-900/50">
                            <button onClick={() => {AudioEngine.play('click'); setShowComplexityModal(false);}}
                                className="premium-button w-full px-4 py-2 text-sm bg-slate-700 hover:bg-slate-600 rounded-lg font-bold">CLOSE REPORT</button>
                        </div>
                    </div>
                </div>
            )}
            
            {/* 5. Narrative Flow Auditor Modal */}
            {showFlowModal && flowReport && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => setShowFlowModal(false)}>
                    <div className="glass-pane rounded-xl w-full max-w-4xl max-h-[90vh] flex flex-col border-purple-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 flex justify-between items-center border-b-2 border-cyan-500/50">
                            <h2 className="font-extrabold text-xl text-purple-400 flex items-center gap-2"><TrendingUp size={20}/> NARRATIVE FLOW AUDITOR</h2>
                            <button onClick={() => { AudioEngine.play('click'); setShowFlowModal(false); }} className="p-1 rounded-full hover:bg-slate-700"><X size={20} /></button>
                        </div>
                        <div className="p-4 overflow-y-auto">
                            <p className='text-xs text-slate-400 font-mono border-b border-slate-700 pb-2 mb-4'>DRAMATURGICAL ANALYSIS OF SCRIPT PACING AND COHERENCE</p>
                            <div className='markdown text-sm text-cyan-200 whitespace-pre-wrap' dangerouslySetInnerHTML={{ __html: flowReport }}></div>
                        </div>
                        <div className="p-4 mt-auto border-t-2 border-cyan-500/50 bg-slate-900/50">
                            <button onClick={() => {AudioEngine.play('click'); setShowFlowModal(false);}}
                                className="premium-button w-full px-4 py-2 text-sm bg-slate-700 hover:bg-slate-600 rounded-lg font-bold">CLOSE REPORT</button>
                        </div>
                    </div>
                </div>
            )}
            
            {/* 6. Visual Asset Descriptor Modal */}
            {showAssetDescModal && assetDescReport && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => setShowAssetDescModal(false)}>
                    <div className="glass-pane rounded-xl w-full max-w-4xl max-h-[90vh] flex flex-col border-yellow-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 flex justify-between items-center border-b-2 border-cyan-500/50">
                            <h2 className="font-extrabold text-xl text-yellow-400 flex items-center gap-2"><Map size={20}/> VISUAL ASSET DESCRIPTOR</h2>
                            <button onClick={() => { AudioEngine.play('click'); setShowAssetDescModal(false); }} className="p-1 rounded-full hover:bg-slate-700"><X size={20} /></button>
                        </div>
                        <div className="p-4 overflow-y-auto">
                            <p className='text-xs text-slate-400 font-mono border-b border-slate-700 pb-2 mb-4'>TECHNICAL FABRICATION MANIFEST FOR: {assetDescPrompt.toUpperCase()}</p>
                            <div className='markdown text-sm text-cyan-200 whitespace-pre-wrap' dangerouslySetInnerHTML={{ __html: assetDescReport }}></div>
                        </div>
                        <div className="p-4 mt-auto border-t-2 border-cyan-500/50 bg-slate-900/50">
                            <button onClick={() => {AudioEngine.play('click'); setShowAssetDescModal(false);}}
                                className="premium-button w-full px-4 py-2 text-sm bg-slate-700 hover:bg-slate-600 rounded-lg font-bold">CLOSE MANIFEST</button>
                        </div>
                    </div>
                </div>
            )}

            {/* 7. Script Purity Filter Modal (NEW) */}
            {showPurityModal && purityReport && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => setShowPurityModal(false)}>
                    <div className="glass-pane rounded-xl w-full max-w-4xl max-h-[90vh] flex flex-col border-teal-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 flex justify-between items-center border-b-2 border-cyan-500/50">
                            <h2 className="font-extrabold text-xl text-teal-400 flex items-center gap-2"><BookOpen size={20}/> SCRIPT PURITY FILTER</h2>
                            <button onClick={() => { AudioEngine.play('click'); setShowPurityModal(false); }} className="p-1 rounded-full hover:bg-slate-700"><X size={20} /></button>
                        </div>
                        <div className="p-4 overflow-y-auto">
                            <p className='text-xs text-slate-400 font-mono border-b border-slate-700 pb-2 mb-4'>ACTIONABLE FEEDBACK ON DIALOGUE, STRUCTURE, AND CLICHÉS</p>
                            <div className='markdown text-sm text-cyan-200 whitespace-pre-wrap' dangerouslySetInnerHTML={{ __html: purityReport }}></div>
                        </div>
                        <div className="p-4 mt-auto border-t-2 border-cyan-500/50 bg-slate-900/50">
                            <button onClick={() => {AudioEngine.play('click'); setShowPurityModal(false);}}
                                className="premium-button w-full px-4 py-2 text-sm bg-slate-700 hover:bg-slate-600 rounded-lg font-bold">CLOSE REPORT</button>
                        </div>
                    </div>
                </div>
            )}
            
            {/* 8. Settings Modal */}
            {showSettings && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => setShowSettings(false)}>
                    <div className="glass-pane rounded-xl w-full max-w-lg border-cyan-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 flex justify-between items-center border-b-2 border-cyan-500/50">
                            <h2 className="font-extrabold text-xl text-cyan-400 flex items-center gap-2"><Settings size={20}/> SYSTEM CONSOLE (V.3000)</h2>
                            <button onClick={() => { AudioEngine.play('click'); setShowSettings(false); }} className="p-1 rounded-full hover:bg-slate-700"><X size={20} /></button>
                        </div>
                        <div className="p-4 space-y-4">
                            <VisionDetail title="EXTERNAL API KEY (PERSISTED LOCALLY)">
                                <input
                                    type="password"
                                    value={apiKey}
                                    onChange={e => setApiKey(e.target.value)}
                                    placeholder="Enter your Google AI Studio API Key"
                                    className="w-full bg-slate-800/70 border-cyan-700 rounded-md p-2 text-sm font-mono text-white focus:ring-cyan-500 focus:border-cyan-500 input-active-glow"
                                />
                                <p className="text-xs text-slate-500 mt-2 font-mono">
                                    KEY IS AUTO-SAVED TO LOCAL INDEXEDDB STORAGE UPON INPUT.
                                </p>
                            </VisionDetail>
                            <VisionDetail title="CORE AI MODEL STATUS">
                                <p className="font-mono text-xs text-cyan-400">TEXT/VISION: gemini-2.5-flash-preview-05-20</p>
                                <p className="font-mono text-xs text-cyan-400">IMAGE/EDIT/CONTINUITY: gemini-2.5-flash-image-preview</p>
                                <p className="font-mono text-xs text-cyan-400">VOICEOVER: gemini-2.5-flash-preview-tts</p>
                            </VisionDetail>
                        </div>
                        <div className="p-4 mt-auto border-t-2 border-cyan-500/50 bg-slate-900/50">
                            <button onClick={() => {AudioEngine.play('click'); setShowSettings(false);}}
                                className="premium-button w-full px-4 py-2 text-sm bg-slate-700 hover:bg-slate-600 rounded-lg font-bold">CLOSE CONSOLE</button>
                        </div>
                    </div>
                </div>
            )}

            {/* 9. History Log Modal */}
            {showHistoryModal && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => setShowHistoryModal(false)}>
                    <div className="glass-pane rounded-xl w-full max-w-3xl max-h-[90vh] flex flex-col border-cyan-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 flex justify-between items-center border-b-2 border-cyan-500/50">
                            <h2 className="font-extrabold text-xl text-cyan-400 flex items-center gap-2"><Clock size={20}/> PROJECT HISTORY LOG</h2>
                            <button onClick={() => { AudioEngine.play('click'); setShowHistoryModal(false); }} className="p-1 rounded-full hover:bg-slate-700"><X size={20} /></button>
                        </div>
                        <div className="p-4 overflow-y-auto space-y-4">
                            {historyItems.length === 0 ? (
                                <p className="text-slate-400 text-center py-8 font-mono">LOG EMPTY. GENERATE A PROJECT TO SAVE STATE.</p>
                            ) : (
                                <div className="divide-y divide-slate-800">
                                    {historyItems.map((item) => (
                                        <div key={item.timestamp} className="py-3 px-3 hover:bg-slate-900/50 rounded-lg transition duration-150 group flex justify-between items-start">
                                            <div className='flex-1 pr-4'>
                                                <div className='flex justify-between items-center'>
                                                    <h3 className="text-sm font-extrabold text-cyan-300">
                                                        {item.config.scriptFile || `PROJECT ID: ${new Date(item.timestamp).getTime().toString().slice(-6)}`}
                                                    </h3>
                                                    <p className="text-xs text-slate-500 font-mono">
                                                        {new Date(item.timestamp).toLocaleDateString()}
                                                    </p>
                                                </div>
                                                <p className="text-xs text-slate-400 mt-1 font-mono">
                                                    <span className="font-semibold text-cyan-500">THEME:</span> {item.vision?.core_theme || 'N/A'} | <span className="font-semibold text-cyan-500">FRAMES:</span> {item.scenes.length} | <span className="font-semibold text-cyan-500">COST:</span> ${item.cost.toFixed(2)}
                                                </p>
                                                <div className="mt-2 flex space-x-2 overflow-x-auto pb-1">
                                                    {item.scenes.slice(0, 5).map((s, i) => (
                                                        <img key={i} src={s.image || `https://placehold.co/60x34/0f172a/707070?text=${s.status.slice(0,1)}`}
                                                            alt={`Scene ${i}`}
                                                            className="w-16 h-9 object-cover rounded-md border border-slate-700 group-hover:border-cyan-400/50" />
                                                    ))}
                                                    {item.scenes.length > 5 && <span className="text-xs text-slate-500 self-center pl-2 font-mono">+{item.scenes.length - 5}</span>}
                                                </div>
                                            </div>
                                            <button onClick={() => { AudioEngine.play('click'); loadHistoryItem(item); }}
                                                className="premium-button flex-shrink-0 text-xs px-3 py-1.5 rounded-lg bg-cyan-700/50 hover:bg-cyan-600/70 border border-cyan-500/50 self-center font-bold">
                                                <span className='flex items-center gap-1'><RotateCw size={12}/> RELOAD STATE</span>
                                            </button>
                                        </div>
                                    ))}
                                </div>
                            )}
                        </div>
                        <div className="p-4 mt-auto border-t-2 border-cyan-500/50 bg-slate-900/50">
                            <button onClick={() => {AudioEngine.play('click'); setShowHistoryModal(false);}}
                                className="premium-button w-full px-4 py-2 text-sm bg-slate-700 hover:bg-slate-600 rounded-lg font-bold">CLOSE LOG</button>
                        </div>
                    </div>
                </div>
            )}
            
            {/* 10. Viral Video Architect Modal */}
            {showViralModal && viralIdeas && (
                <div className="fixed inset-0 z-[60] bg-black/90 backdrop-blur-lg flex items-center justify-center p-4" onClick={() => setShowViralModal(false)}>
                    <div className="glass-pane rounded-xl w-full max-w-5xl max-h-[90vh] flex flex-col border-green-400/40" onClick={e => e.stopPropagation()}>
                        <div className="p-4 flex justify-between items-center border-b-2 border-cyan-500/50">
                            <h2 className="font-extrabold text-xl text-green-400 flex items-center gap-2">
                                <ZapIcon size={20}/> VIRAL VIDEO ARCHITECT REPORT ({viralMode === 'ads' ? 'AD CONCEPTS' : 'GENERAL CONCEPTS'})
                            </h2>
                            <button onClick={() => { AudioEngine.play('click'); setShowViralModal(false); }} className="p-1 rounded-full hover:bg-slate-700"><X size={20} /></button>
                        </div>
                        <div className="p-4 overflow-y-auto space-y-4">
                            <p className='text-xs text-slate-400 font-mono border-b border-slate-700 pb-2'>10 BIZARRE, 8-SECOND VIRAL CONCEPTS GENERATED BY GEMINI AI</p>
                            
                            <div className="space-y-4">
                                {viralIdeas.map((idea, index) => (
                                    <div key={idea.id} className="p-4 bg-slate-900/50 rounded-lg border border-green-700/50 hover:border-green-400/70 transition-all duration-200">
                                        <div className='flex justify-between items-start'>
                                            <h3 className="font-extrabold text-lg text-cyan-300 flex items-center gap-3">
                                                {index + 1}. {idea.concept_title}
                                            </h3>
                                            <GenreTag genre={idea.genre} />
                                        </div>
                                        
                                        <div className='mt-2 grid grid-cols-1 lg:grid-cols-3 gap-4'>
                                            {/* Left: Script & Prompt */}
                                            <div className='lg:col-span-2 space-y-1 text-xs font-mono text-slate-400'>
                                                <p><span className='font-extrabold text-green-300'>8-Second Script:</span> {idea.eight_second_script}</p>
                                                
                                                {/* Veo 3 Prompt */}
                                                <p className='mt-2 p-2 bg-slate-800/70 rounded-md border border-green-700'>
                                                    <span className='font-extrabold text-red-400 flex items-center'><Video size={14} className='mr-1'/>VEO 3 IMAGE-TO-VIDEO PROMPT:</span> 
                                                    <span className='block mt-1 text-yellow-300'>{idea.veo3_prompt}</span>
                                                    <button onClick={() => { navigator.clipboard.writeText(idea.veo3_prompt); AudioEngine.play('click'); setStatus('Veo 3 Prompt Copied.'); }}
                                                        className="premium-button flex items-center gap-1 text-xs px-2 py-1 rounded-full bg-green-600/50 hover:bg-green-500/70 mt-2">
                                                        <ClipboardCheck size={12}/> COPY VEO PROMPT
                                                    </button>
                                                </p>
                                                
                                                {/* First Frame Prompt (Image Ref) */}
                                                <p className='mt-2 p-2 bg-slate-800/70 rounded-md border border-slate-700'>
                                                    <span className='font-extrabold text-yellow-400'>First Frame Prompt:</span> {idea.first_frame_prompt}
                                                </p>
                                            </div>
                                            
                                            {/* Right: First Frame Image Generation (Actual API Call) */}
                                            <div className='lg:col-span-1 relative'>
                                                <div 
                                                    className={cn(
                                                        "aspect-[16/9] border-2 rounded-lg flex items-center justify-center text-center p-2",
                                                        idea.frameStatus === 'pending' && "bg-slate-900 border-green-500/50 cursor-pointer hover:border-green-300/80 transition-all",
                                                        idea.frameStatus === 'generating' && "bg-black/80 border-blue-500 animate-pulse",
                                                        idea.frameStatus === 'success' && "border-green-500/80",
                                                        idea.frameStatus === 'error' && "bg-red-900/50 border-red-500/80"
                                                    )}
                                                    onClick={() => {
                                                        if (idea.frameStatus === 'pending' || idea.frameStatus === 'error') {
                                                            generateViralIdeaFrame(idea.id, idea.first_frame_prompt);
                                                        }
                                                    }}
                                                >
                                                    {idea.frameStatus === 'generating' ? (
                                                        <Loader2 size={32} className="animate-spin text-blue-400" />
                                                    ) : idea.frameImage ? (
                                                        <>
                                                            <img src={idea.frameImage} alt={`Frame for ${idea.concept_title}`} className="w-full h-full object-cover rounded" />
                                                            <button onClick={(e) => {
                                                                e.stopPropagation();
                                                                const a = document.createElement('a');
                                                                a.href = idea.frameImage;
                                                                a.download = `Viral_Frame_${idea.id}.png`;
                                                                a.click();
                                                                AudioEngine.play('success');
                                                            }} className="absolute top-2 right-2 p-1 bg-black/60 rounded-full hover:bg-cyan-600 transition">
                                                                <Download size={14} className='text-white'/>
                                                            </button>
                                                        </>
                                                    ) : (
                                                        <span className="text-xs text-green-400 font-mono italic">
                                                            {idea.frameStatus === 'error' ? 'SYNTHESIS ERROR. CLICK TO RETRY.' : 'FRAME SYNTHESIS PENDING. CLICK TO GENERATE ($0.10).'}
                                                        </span>
                                                    )}
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                ))}
                            </div>
                        </div>
                        <div className="p-4 mt-auto border-t-2 border-cyan-500/50 bg-slate-900/50">
                            <button onClick={() => {AudioEngine.play('click'); setShowViralModal(false);}}
                                className="premium-button w-full px-4 py-2 text-sm bg-slate-700 hover:bg-slate-600 rounded-lg font-bold">DISMISS REPORT</button>
                        </div>
                    </div>
                </div>
            )}
        </div>
    );
}

// Simple component for Vision Modal detail
const VisionDetail = ({ title, children }) => (
    <div class="space-y-1">
        <h3 class="font-extrabold text-cyan-300 uppercase font-mono">{title}:</h3>
        <div class="text-xs p-2 bg-slate-900/70 rounded-lg whitespace-pre-wrap border border-cyan-700 text-cyan-400 font-mono">{children}</div>
    </div>
);

// Helper component for genre tags
const GenreTag = ({ genre }) => {
    let colorClass = 'bg-slate-700 text-slate-300';
    if (genre.includes('Comedy')) colorClass = 'bg-yellow-600/50 text-yellow-200 border-yellow-700';
    else if (genre.includes('Action')) colorClass = 'bg-red-600/50 text-red-200 border-red-700';
    else if (genre.includes('Chaos')) colorClass = 'bg-fuchsia-600/50 text-fuchsia-200 border-fuchsia-700';
    else if (genre.includes('Informative')) colorClass = 'bg-blue-600/50 text-blue-200 border-blue-700';
    else if (genre.includes('ASMR')) colorClass = 'bg-lime-600/50 text-lime-200 border-lime-700';
    else if (genre.includes('Thriller')) colorClass = 'bg-purple-600/50 text-purple-200 border-purple-700';
    else if (genre.includes('Emotional')) colorClass = 'bg-pink-600/50 text-pink-200 border-pink-700';
    else if (genre.includes('Dance')) colorClass = 'bg-cyan-600/50 text-cyan-200 border-cyan-700';
    return <span className={`text-xs font-mono font-bold px-2 py-0.5 rounded-full border ${colorClass}`}>{genre.toUpperCase()}</span>;
};
